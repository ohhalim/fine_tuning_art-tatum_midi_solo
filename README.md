# Art Tatum AI - Fine-tuning Project

ğŸ¹ **TatumFlow**: Hierarchical Latent Diffusion for Jazz Improvisation

ì‹¤ì‹œê°„ Art Tatum ìŠ¤íƒ€ì¼ ì¬ì¦ˆ ì†”ë¡œ ìƒì„± AI

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/ohhalim/fine_tuning_art-tatum_midi_solo.git
cd fine_tuning_art-tatum_midi_solo

# Install dependencies
pip install -r requirements.txt
```

### Generate Music (Using Pre-trained Model)

```bash
# Generate continuation
python scripts/generate_music.py \
  --checkpoint checkpoints/best.pt \
  --mode continuation \
  --prompt input.mid \
  --output output.mid \
  --num_tokens 512

# Generate Art Tatum-style improvisations
python scripts/generate_music.py \
  --checkpoint checkpoints/best.pt \
  --mode improvise \
  --prompt input.mid \
  --output improvisation.mid \
  --num_variations 5 \
  --creativity 0.7

# Style transfer
python scripts/generate_music.py \
  --checkpoint checkpoints/best.pt \
  --mode style_transfer \
  --prompt classical.mid \
  --target_style jazz.mid \
  --output jazz_style.mid
```

### Train Your Own Model

```bash
# 1. Prepare MIDI data
mkdir -p data/midi
# Copy your MIDI files to data/midi/

# 2. Edit config.yaml if needed
nano config.yaml

# 3. Train
python scripts/train_tatumflow.py
```

---

## ğŸ“š í”„ë¡œì íŠ¸ êµ¬ì¡°

```
fine_tuning_art-tatum_midi_solo/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ tatumflow/          # TatumFlow ëª¨ë¸ êµ¬í˜„
â”‚       â”œâ”€â”€ model.py        # í•µì‹¬ ì•„í‚¤í…ì²˜
â”‚       â”œâ”€â”€ tokenizer.py    # MIDI í† í¬ë‚˜ì´ì €
â”‚       â”œâ”€â”€ dataset.py      # ë°ì´í„° ë¡œë”
â”‚       â”œâ”€â”€ train.py        # í•™ìŠµ íŒŒì´í”„ë¼ì¸
â”‚       â”œâ”€â”€ generate.py     # ìƒì„± ì—”ì§„
â”‚       â””â”€â”€ utils.py        # ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_tatumflow.py  # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ generate_music.py   # ìƒì„± ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ model_analysis.md   # ImprovNet vs Magenta RT ë¶„ì„
â”‚   â””â”€â”€ tatumflow_architecture.md  # TatumFlow ì•„í‚¤í…ì²˜ ë¬¸ì„œ
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Magenta_RT_Demo.ipynb
â”œâ”€â”€ data/                   # ë°ì´í„°ì…‹ (gitignored)
â”œâ”€â”€ checkpoints/            # í•™ìŠµëœ ëª¨ë¸ (gitignored)
â”œâ”€â”€ logs/                   # í•™ìŠµ ë¡œê·¸ (gitignored)
â”œâ”€â”€ config.yaml             # ì„¤ì • íŒŒì¼
â””â”€â”€ requirements.txt

```

---

## ğŸ¯ TatumFlow íŠ¹ì§•

### í˜ì‹ ì  ì•„í‚¤í…ì²˜

1. **Hierarchical Latent Diffusion**
   - Symbolic ë„ë©”ì¸ì— latent diffusion ìµœì´ˆ ì ìš©
   - 50 ìŠ¤í…ìœ¼ë¡œ ê³ í’ˆì§ˆ ìƒì„± (ê¸°ì¡´ 1000 ìŠ¤í… ëŒ€ë¹„ 20ë°° ë¹ ë¦„)

2. **Multi-Scale Temporal Modeling**
   - Note, Beat, Phrase ë ˆë²¨ ë™ì‹œ ëª¨ë¸ë§
   - ë¡œì»¬/ê¸€ë¡œë²Œ íŒ¨í„´ ëª¨ë‘ ìº¡ì²˜

3. **Explicit Music Theory Disentanglement**
   - Harmony, Melody, Rhythm, Dynamics ë¶„ë¦¬ ì¸ì½”ë”©
   - ê° ìš”ì†Œ ë…ë¦½ì  ì œì–´ ê°€ëŠ¥

4. **Style VAE**
   - ì—°ì†ì ì¸ ìŠ¤íƒ€ì¼ ê³µê°„
   - ë¶€ë“œëŸ¬ìš´ ìŠ¤íƒ€ì¼ ë³´ê°„
   - ì°½ì˜ì„± ì •ë„ ì¡°ì ˆ ê°€ëŠ¥

### ìƒì„± ëª¨ë“œ

| ëª¨ë“œ | ì„¤ëª… | ì‚¬ìš© ì˜ˆì‹œ |
|------|------|-----------|
| **Continuation** | í”„ë¡¬í”„íŠ¸ ì´ì–´ì„œ ìƒì„± | ê³¡ ì™„ì„±, ì¦‰í¥ ì—°ì£¼ ì—°ìŠµ |
| **Style Transfer** | ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜ | í´ë˜ì‹ â†’ ì¬ì¦ˆ ë³€í™˜ |
| **Improvise** | ë³€ì£¼ ìƒì„± | Art Tatum ìŠ¤íƒ€ì¼ ë³€ì£¼ |
| **Theory Edit** | ìŒì•… ì´ë¡  í¸ì§‘ | íŠ¹ì • ì½”ë“œ ì§„í–‰ ì‚½ì… |

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸ | ë„ë©”ì¸ | ì œì–´ì„± | í’ˆì§ˆ | ì†ë„ | í¸ì§‘ì„± |
|------|--------|--------|------|------|--------|
| ImprovNet | Symbolic | â­â­â­â­â­ | â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| Magenta RT | Audio | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­ |
| **TatumFlow** | **Symbolic** | **â­â­â­â­â­** | **â­â­â­â­â­** | **â­â­â­â­** | **â­â­â­â­â­** |

### TatumFlow ì¥ì 

âœ… **ImprovNet ëŒ€ë¹„**:
- ë” ë¶€ë“œëŸ¬ìš´ ìŠ¤íƒ€ì¼ ì „ì´ (continuous latent space)
- ë¹ ë¥¸ ì¶”ë¡  (50 diffusion steps vs ë‹¤ì¤‘ refinement passes)
- ëª…ì‹œì  ìŒì•… ì´ë¡  ì œì–´

âœ… **Magenta RT ëŒ€ë¹„**:
- Symbolic domain (í¸ì§‘ ê°€ëŠ¥, DAW í†µí•© ìš©ì´)
- ëª…ì‹œì  ì œì–´ (vs ë¸”ë™ë°•ìŠ¤ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸)
- ê²°ì •ë¡ ì  ìƒì„± (ë™ì¼ ì…ë ¥ â†’ ë™ì¼ ì¶œë ¥)
- ë‚®ì€ ë¦¬ì†ŒìŠ¤ (Consumer GPUì—ì„œ ì‹¤í–‰ ê°€ëŠ¥)

---

## ğŸ”¬ Model Architecture

### Core Components

```python
TatumFlow(
  vocab_size=2048,          # í† í° ìˆ˜
  hidden_dim=512,           # Hidden dimension
  latent_dim=256,           # Latent dimension
  num_layers=12,            # Transformer layers
  num_heads=8,              # Attention heads
  diffusion_steps=1000,     # Diffusion timesteps
  num_style_dims=64         # Style vector dimension
)
```

### Model Sizes

| Size | Params | VRAM | Training Time (100 epochs) |
|------|--------|------|----------------------------|
| Small | 45M | 4GB | ~1 day |
| Base | 110M | 8GB | ~3 days |
| Large | 350M | 16GB | ~7 days |

### Technical Innovations

1. **Rotary Positional Embedding (RoPE)**: Better position encoding
2. **AdaLN (Adaptive Layer Normalization)**: Time-conditioned modulation
3. **Cosine Noise Schedule**: Smoother diffusion process
4. **Multi-objective Loss**: Reconstruction + Diffusion + KL + Theory

---

## ğŸ“– Documentation

- **[Model Analysis](docs/model_analysis.md)**: ImprovNet vs Magenta Realtime ìƒì„¸ ë¹„êµ
- **[Architecture](docs/tatumflow_architecture.md)**: TatumFlow ì•„í‚¤í…ì²˜ ì „ì²´ ë¬¸ì„œ
- **[Config Reference](config.yaml)**: ì„¤ì • íŒŒì¼ ê°€ì´ë“œ

---

## ğŸ“ Training Guide

### 1. ë°ì´í„° ì¤€ë¹„

```bash
# PiJAMA dataset download (example)
# Download from: https://github.com/SonyCSLParis/pijama

# Art Tatum filtering (automatic in dataset.py)
# Filters by artist name in file path
```

### 2. ì„¤ì • ìˆ˜ì •

```yaml
# config.yaml
data:
  data_dir: "data/midi"      # MIDI íŒŒì¼ ê²½ë¡œ
  pijama_dir: "data/pijama"  # PiJAMA ê²½ë¡œ
  artist_filter: "art tatum"

training:
  batch_size: 4
  num_epochs: 100
  learning_rate: 1e-4
```

### 3. í•™ìŠµ ì‹¤í–‰

```bash
# Single GPU
python scripts/train_tatumflow.py

# Monitor with TensorBoard
tensorboard --logdir logs/
```

### 4. ì²´í¬í¬ì¸íŠ¸

í•™ìŠµ ì¤‘ ìƒì„±ë˜ëŠ” ì²´í¬í¬ì¸íŠ¸:
- `checkpoints/latest.pt`: ìµœì‹  ì²´í¬í¬ì¸íŠ¸
- `checkpoints/best.pt`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- `checkpoints/epoch_N.pt`: 10 ì—í­ë§ˆë‹¤ ì €ì¥

---

## ğŸ’¡ Usage Examples

### Python API

```python
from tatumflow import (
    TatumFlow,
    TatumFlowTokenizer,
    TatumFlowGenerator,
    load_model_from_checkpoint
)

# Load model
model, tokenizer = load_model_from_checkpoint('checkpoints/best.pt')

# Create generator
generator = TatumFlowGenerator(model, tokenizer, device='cuda')

# Generate continuation
generated = generator.generate_continuation(
    prompt_midi='input.mid',
    num_tokens=512,
    temperature=1.0,
    top_k=50,
    top_p=0.95
)

# Save MIDI
generator.tokens_to_midi(generated, 'output.mid')

# Style transfer
transferred = generator.style_transfer(
    source_midi='classical.mid',
    target_style_midi='art_tatum.mid',
    num_iterations=3,
    denoise_strength=0.7
)

# Generate variations
variations = generator.improvise(
    base_midi='input.mid',
    num_variations=5,
    creativity=0.7,
    preserve_structure=True
)
```

---

## ğŸ› ï¸ Advanced Features

### 1. Custom Corruption Functions

```python
# Add your own corruption function
def my_corruption(tokens):
    # Custom logic
    return corrupted_tokens

# Use during training
trainer.add_corruption_function('my_corruption', my_corruption)
```

### 2. Style Interpolation

```python
# Mix two styles
style_a, _, _ = model.encode_style(tokens_a)
style_b, _, _ = model.encode_style(tokens_b)

# Linear interpolation
alpha = 0.5
mixed_style = alpha * style_a + (1 - alpha) * style_b

# Generate with mixed style
output = generator.generate_continuation(
    prompt_midi='input.mid',
    style=mixed_style
)
```

### 3. Theory-Guided Generation

```python
# Extract and modify music theory components
outputs = model(tokens)
components = outputs['theory_components']

# Modify harmony
components['harmony'] = modify_to_chord_progression(
    components['harmony'],
    chords=['Dm7', 'G7', 'CMaj7']
)

# Regenerate with new theory
output = model.generate_with_theory(components, style)
```

---

## ğŸ“ˆ Roadmap

### âœ… Completed
- [x] ImprovNet & Magenta RT ë¶„ì„
- [x] TatumFlow ì•„í‚¤í…ì²˜ ì„¤ê³„
- [x] í•µì‹¬ ëª¨ë¸ êµ¬í˜„
- [x] í† í¬ë‚˜ì´ì € êµ¬í˜„
- [x] í•™ìŠµ íŒŒì´í”„ë¼ì¸
- [x] ìƒì„± ì—”ì§„
- [x] ë¬¸ì„œí™”

### ğŸš§ In Progress
- [ ] Pre-training on classical music
- [ ] Fine-tuning on Art Tatum data
- [ ] Human evaluation study

### ğŸ“‹ Planned
- [ ] Multi-track support
- [ ] Real-time generation
- [ ] Web demo
- [ ] Mobile deployment
- [ ] Audio-symbolic hybrid model

---

## ğŸ¤ Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

- **ImprovNet** (Bhandari et al.): Corruption-refinement inspiration
- **Magenta Realtime** (Google): Real-time generation insights
- **Aria Tokenizer** (EleutherAI): Tokenization approach
- **Stable Diffusion** (Stability AI): Latent diffusion methodology
- **DiT** (Meta): Diffusion transformer architecture

---

## ğŸ“ Contact

- **GitHub**: [@ohhalim](https://github.com/ohhalim)
- **Project Link**: [fine_tuning_art-tatum_midi_solo](https://github.com/ohhalim/fine_tuning_art-tatum_midi_solo)

---

## ğŸ“š Citation

If you use TatumFlow in your research, please cite:

```bibtex
@software{tatumflow2025,
  title={TatumFlow: Hierarchical Latent Diffusion for Jazz Improvisation},
  author={TatumFlow Team},
  year={2025},
  url={https://github.com/ohhalim/fine_tuning_art-tatum_midi_solo}
}
```

---

**Built with â¤ï¸ for the jazz community**
