# ğŸ¹ Brad Mehldau AI Generator

**SCG + Transformer í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸**ë¡œ Brad Mehldau ìŠ¤íƒ€ì¼ì˜ ì¬ì¦ˆ í”¼ì•„ë…¸ ì†”ë¡œë¥¼ ì‹¤ì‹œê°„ ìƒì„±

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/pytorch-2.0+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

---

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- ğŸ¼ **ì½”ë“œ ì§„í–‰ ê¸°ë°˜ ìƒì„±**: Cmaj7 â†’ Dm7 â†’ G7 â†’ Cmaj7 ì…ë ¥ â†’ Brad Mehldau ìŠ¤íƒ€ì¼ ì†”ë¡œ ì¶œë ¥
- ğŸš€ **ìµœì‹  ê¸°ìˆ  ê²°í•©**: SCG Diffusion + Transformer Style Encoder
- ğŸ¹ **FL Studio ì‹¤ì‹œê°„ í†µí•©**: loopMIDIë¡œ DAWì™€ ì—°ê²°
- âš¡ **ë¹ ë¥¸ ì¶”ë¡ **: DDIM 50 steps (< 1ì´ˆ, GPU ê¸°ì¤€)
- ğŸ¨ **ì°½ì˜ì„± ì¡°ì ˆ**: Temperature & Guidance Scale íŒŒë¼ë¯¸í„°

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
ì…ë ¥: ì½”ë“œ ì§„í–‰ ['Cmaj7', 'Dm7', 'G7', 'Cmaj7']
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Brad Mehldau Style Encoder Transformer â”‚  â† 8-layer BERT-like
â”‚  (ì½”ë“œ ì„ë² ë”© + ìŠ¤íƒ€ì¼ íŠ¹ì§• ì¶”ì¶œ)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ style_embedding [256]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DiT (Diffusion Transformer)            â”‚  â† 12-layer, 6-head
â”‚  + VQ-VAE Latent Diffusion              â”‚
â”‚  + DDIM Sampling (50 steps)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ latent [64, 32, 64]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VQ-VAE Decoder                         â”‚  â† Piano roll ì¬êµ¬ì„±
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
ì¶œë ¥: Piano Roll [2, 128, time]
      â†“
    MIDI Notes â†’ FL Studio
```

---

## ğŸ“¦ ì„¤ì¹˜

### ìš”êµ¬ì‚¬í•­

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (GPU í•™ìŠµìš©)

### ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/yourusername/brad-mehldau-ai.git
cd brad-mehldau-ai

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# MIDI í†µì‹  (FL Studio í†µí•©ìš©)
pip install mido python-rtmidi
```

---

## ğŸš€ Quick Start

### 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš©)

```bash
python scripts/download_data.py --dataset test
```

### 2. í•™ìŠµ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)

```bash
# VQ-VAE ì‚¬ì „í•™ìŠµ
python scripts/train_vqvae.py --test --epochs 5

# ì²´í¬í¬ì¸íŠ¸ í™•ì¸
ls checkpoints/vqvae/
```

### 3. ì¶”ë¡  í…ŒìŠ¤íŠ¸

```python
from src.models.hybrid_model import SCGTransformerHybrid

# ëª¨ë¸ ë¡œë“œ
model = SCGTransformerHybrid()
model.eval()

# ìƒì„±
chord_progression = ['Cmaj7', 'Dm7', 'G7', 'Cmaj7']
piano_roll = model.generate(
    chord_progression=chord_progression,
    num_steps=50,
    guidance_scale=7.5,
    temperature=0.8
)

print(f"Generated: {piano_roll.shape}")
```

---

## ğŸ“š ë¬¸ì„œ

- **[Training Guide](docs/TRAINING_GUIDE.md)**: Runpod/Colab í•™ìŠµ ê°€ì´ë“œ
- **[FL Studio Integration](docs/FL_STUDIO_GUIDE.md)**: DAW í†µí•© ì„¤ì •
- **[API Reference](docs/API.md)**: ëª¨ë¸ API ë¬¸ì„œ

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
brad-mehldau-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ vqvae.py              # VQ-VAE ì¸ì½”ë”/ë””ì½”ë”
â”‚   â”‚   â”œâ”€â”€ dit.py                # Diffusion Transformer
â”‚   â”‚   â”œâ”€â”€ style_encoder.py      # Brad Mehldau Style Encoder
â”‚   â”‚   â””â”€â”€ hybrid_model.py       # í†µí•© ëª¨ë¸
â”‚   â”œâ”€â”€ training/                 # í•™ìŠµ ìœ í‹¸
â”‚   â””â”€â”€ utils/                    # ê³µí†µ ìœ í‹¸
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_data.py          # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
â”‚   â”œâ”€â”€ train_vqvae.py           # VQ-VAE í•™ìŠµ
â”‚   â”œâ”€â”€ train_style_encoder.py   # Style Encoder í•™ìŠµ
â”‚   â””â”€â”€ train_hybrid.py          # Hybrid ëª¨ë¸ fine-tuning
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ inference_server.py      # ì¶”ë¡  ì„œë²„
â”‚   â””â”€â”€ midi_server.py           # MIDI í†µì‹  ì„œë²„
â”‚
â”œâ”€â”€ data/                        # ë°ì´í„°ì…‹
â”œâ”€â”€ checkpoints/                 # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ configs/                     # ì„¤ì • íŒŒì¼
â””â”€â”€ docs/                        # ë¬¸ì„œ
```

---

## ğŸ¯ í•™ìŠµ íŒŒì´í”„ë¼ì¸

### Phase 1: VQ-VAE ì‚¬ì „í•™ìŠµ (Week 1-2)

```bash
# MAESTRO ë°ì´í„°ë¡œ VQ-VAE í•™ìŠµ
python scripts/download_data.py --dataset maestro
python scripts/train_vqvae.py \
  --data_dir ./data/maestro \
  --epochs 50 \
  --batch_size 16
```

**ì˜ˆìƒ ì‹œê°„**: RTX 3090 ê¸°ì¤€ 8-10ì‹œê°„
**ë¹„ìš©**: Runpod ~$3

### Phase 2: Style Encoder í•™ìŠµ (Week 3-4)

```bash
# PiJAMA ë°ì´í„°ë¡œ Style Encoder í•™ìŠµ
python scripts/download_data.py --dataset pijama
python scripts/train_style_encoder.py \
  --data_dir ./data/pijama \
  --epochs 50 \
  --batch_size 32
```

**ì˜ˆìƒ ì‹œê°„**: RTX 3090 ê¸°ì¤€ 8-10ì‹œê°„
**ë¹„ìš©**: Runpod ~$3

### Phase 3: Brad Mehldau Fine-tuning (Week 5-6)

```bash
# Brad Mehldau ë°ì´í„°ë¡œ Hybrid ëª¨ë¸ fine-tuning
python scripts/train_hybrid.py \
  --vqvae_ckpt ./checkpoints/vqvae/best.pt \
  --style_encoder_ckpt ./checkpoints/style_encoder/best.pt \
  --brad_data ./data/brad_mehldau \
  --epochs 50 \
  --batch_size 16
```

**ì˜ˆìƒ ì‹œê°„**: RTX 3090 ê¸°ì¤€ 10-15ì‹œê°„
**ë¹„ìš©**: Runpod ~$5

**ì´ ì˜ˆì‚°**: ~$10-15 (Spot instance ì‚¬ìš© ì‹œ)

---

## ğŸ¹ FL Studio í†µí•©

### 1. loopMIDI ì„¤ì¹˜

1. [loopMIDI](https://www.tobias-erichsen.de/software/loopmidi.html) ë‹¤ìš´ë¡œë“œ
2. ê°€ìƒ í¬íŠ¸ 2ê°œ ìƒì„±:
   - `loopMIDI Port 1` (ì¶œë ¥: Python â†’ FL Studio)
   - `loopMIDI Port 2` (ì…ë ¥: FL Studio â†’ Python)

### 2. FL Studio ì„¤ì •

```
Options â†’ MIDI Settings:
  Input:  âœ… loopMIDI Port 2
  Output: âœ… loopMIDI Port 1

Channel Rack:
  Track 1: MIDI Out â†’ Port 2 (ì½”ë“œ ì…ë ¥)
  Track 2: MIDI In â†’ Port 1 (ì†”ë¡œ ìˆ˜ì‹ )
```

### 3. MIDI ì„œë²„ ì‹¤í–‰

```bash
python server/midi_server.py \
  --checkpoint ./checkpoints/brad_final/best.pt \
  --device cuda
```

### 4. ì‚¬ìš©ë²•

1. FL Studioì—ì„œ Track 1ì— ì½”ë“œ 4ê°œ ì—°ì£¼
2. Pythonì´ ìë™ìœ¼ë¡œ Brad Mehldau ì†”ë¡œ ìƒì„±
3. Track 2ë¡œ MIDI ì „ì†¡ â†’ ì‹¤ì‹œê°„ ì¬ìƒ

---

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### ì°½ì˜ì„± ì¡°ì ˆ

```python
# ë³´ìˆ˜ì  (Brad ìŠ¤íƒ€ì¼ì— ì¶©ì‹¤)
piano_roll = model.generate(
    chord_progression=chords,
    temperature=0.5,
    guidance_scale=10.0
)

# ì°½ì˜ì  (ì¦‰í¥ì„± ë†’ìŒ)
piano_roll = model.generate(
    chord_progression=chords,
    temperature=1.2,
    guidance_scale=5.0
)
```

### ì†ë„ ìµœì í™”

```python
# DDIM steps ì¤„ì´ê¸° (í’ˆì§ˆ â†“, ì†ë„ â†‘)
piano_roll = model.generate(
    chord_progression=chords,
    num_steps=25  # 50 â†’ 25 (2ë°° ë¹ ë¦„)
)

# INT8 ì–‘ìí™” (CPU ì¶”ë¡  2-3ë°° ë¹ ë¦„)
generator = BradMehldauGenerator(
    checkpoint_path="./checkpoints/brad_final/best.pt",
    quantize=True
)
```

---

## ğŸ“Š ì„±ëŠ¥

### ìƒì„± ì†ë„

| í™˜ê²½ | DDIM Steps | ì‹œê°„ |
|------|-----------|------|
| RTX 4090 | 50 | ~0.5s |
| RTX 3090 | 50 | ~0.8s |
| M1 Max | 50 | ~3.0s |
| CPU (i7) | 50 | ~12s |

### ëª¨ë¸ í¬ê¸°

| ì»´í¬ë„ŒíŠ¸ | íŒŒë¼ë¯¸í„° | í¬ê¸° |
|---------|---------|------|
| VQ-VAE | ~50M | 200MB |
| DiT | ~120M | 480MB |
| Style Encoder | ~85M | 340MB |
| **Total** | **~255M** | **~1GB** |

---

## ğŸµ ìƒ˜í”Œ

> **Note**: í•™ìŠµ ì™„ë£Œ í›„ ìƒì„±ëœ ìƒ˜í”Œì„ ì—¬ê¸°ì— ì¶”ê°€ ì˜ˆì •

```bash
# ìƒ˜í”Œ ìƒì„±
python scripts/generate_samples.py \
  --checkpoint ./checkpoints/brad_final/best.pt \
  --output ./samples/
```

---

## ğŸ› ï¸ ê°œë°œ ë¡œë“œë§µ

- [x] VQ-VAE êµ¬í˜„
- [x] DiT êµ¬í˜„
- [x] Style Encoder Transformer êµ¬í˜„
- [x] Hybrid ëª¨ë¸ í†µí•©
- [x] MIDI ì„œë²„ êµ¬í˜„
- [ ] ë°ì´í„° ë¡œë” êµ¬í˜„ (TODO)
- [ ] ì½”ë“œ í† í¬ë‚˜ì´ì € êµ¬í˜„ (TODO)
- [ ] Brad Mehldau ë°ì´í„° ìˆ˜ì§‘ (TODO)
- [ ] Fine-tuning ì‹¤í–‰ (TODO)
- [ ] ì„±ëŠ¥ í‰ê°€ (TODO)
- [ ] GUI ì œì–´íŒ (TODO)

---

## ğŸ¤ ê¸°ì—¬

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤!

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ ë¼ì´ì„¼ìŠ¤

MIT License - ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì„¸ìš”!

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- **SCG (Rule-Guided Music)**: VQ-VAE + Diffusion ì•„í‚¤í…ì²˜
- **DiT (Diffusion Transformers)**: Transformer ê¸°ë°˜ diffusion
- **Brad Mehldau**: ì˜ê°ì˜ ì›ì²œ

---

## ğŸ“§ ë¬¸ì˜

- GitHub Issues: ë²„ê·¸ ë¦¬í¬íŠ¸ & ê¸°ëŠ¥ ìš”ì²­
- Email: your.email@example.com

---

**Made with â¤ï¸ for jazz lovers**
