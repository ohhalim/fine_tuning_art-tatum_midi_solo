# TatumFlow Quick Start Guide

## ğŸš€ 5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°

### 1. ì„¤ì¹˜ (1ë¶„)

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/ohhalim/fine_tuning_art-tatum_midi_solo.git
cd fine_tuning_art-tatum_midi_solo

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install torch numpy scipy mido pyyaml tqdm tensorboard matplotlib

# ë˜ëŠ” ì „ì²´ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ëª¨ë¸ í…ŒìŠ¤íŠ¸ (1ë¶„)

```python
import sys
sys.path.insert(0, 'src')

from tatumflow import create_tatumflow_model, TatumFlowTokenizer
import torch

# í† í¬ë‚˜ì´ì € ìƒì„±
tokenizer = TatumFlowTokenizer()
print(f"Vocabulary: {tokenizer.vocab_size} tokens")

# ëª¨ë¸ ìƒì„±
model = create_tatumflow_model('base', vocab_size=tokenizer.vocab_size)
print(f"Parameters: {sum(p.numel() for p in model.parameters()):,}")

# í…ŒìŠ¤íŠ¸
tokens = torch.randint(0, tokenizer.vocab_size, (1, 128))
outputs = model(tokens, timestep=torch.tensor([500]))
print(f"Output shape: {outputs['logits'].shape}")
print("âœ… TatumFlow ready!")
```

### 3. ë°ì´í„° ì¤€ë¹„ (2ë¶„)

```bash
# MIDI íŒŒì¼ ì¤€ë¹„
mkdir -p data/midi
# ì—¬ê¸°ì— MIDI íŒŒì¼ ë³µì‚¬

# ë˜ëŠ” PiJAMA ë‹¤ìš´ë¡œë“œ (Art Tatum ë°ì´í„°)
# git clone https://github.com/SonyCSLParis/pijama data/pijama
```

### 4. í•™ìŠµ ì‹œì‘ (1ë¶„)

```bash
# ì„¤ì • íŒŒì¼ í™•ì¸/ìˆ˜ì •
nano config.yaml

# í•™ìŠµ ì‹¤í–‰
python scripts/train_tatumflow.py

# TensorBoardë¡œ ëª¨ë‹ˆí„°ë§
tensorboard --logdir logs/
```

## ğŸ“– ì£¼ìš” ëª…ë ¹ì–´

### ìŒì•… ìƒì„±

```bash
# 1. Continuation (ê³¡ ì´ì–´ì“°ê¸°)
python scripts/generate_music.py \
  --checkpoint checkpoints/best.pt \
  --mode continuation \
  --prompt input.mid \
  --output output.mid \
  --num_tokens 512

# 2. Improvisation (ì¦‰í¥ ë³€ì£¼)
python scripts/generate_music.py \
  --checkpoint checkpoints/best.pt \
  --mode improvise \
  --prompt input.mid \
  --output improv.mid \
  --num_variations 5 \
  --creativity 0.7

# 3. Style Transfer (ìŠ¤íƒ€ì¼ ë³€í™˜)
python scripts/generate_music.py \
  --checkpoint checkpoints/best.pt \
  --mode style_transfer \
  --prompt classical.mid \
  --target_style jazz.mid \
  --output jazz_version.mid
```

### Python API

```python
from tatumflow import TatumFlowGenerator, load_model_from_checkpoint

# ëª¨ë¸ ë¡œë“œ
model, tokenizer = load_model_from_checkpoint('checkpoints/best.pt')
generator = TatumFlowGenerator(model, tokenizer)

# ìƒì„±
generated = generator.generate_continuation(
    prompt_midi='input.mid',
    num_tokens=512,
    temperature=1.0
)

# ì €ì¥
generator.tokens_to_midi(generated, 'output.mid')
```

## ğŸ¯ ì£¼ìš” íŒŒë¼ë¯¸í„°

### í•™ìŠµ

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|----------|--------|------|
| `batch_size` | 4 | ë°°ì¹˜ í¬ê¸° |
| `learning_rate` | 1e-4 | í•™ìŠµë¥  |
| `num_epochs` | 100 | ì—í­ ìˆ˜ |
| `diffusion_prob` | 0.7 | Diffusion ì‚¬ìš© í™•ë¥  |

### ìƒì„±

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|----------|--------|------|
| `temperature` | 1.0 | ìƒ˜í”Œë§ ì˜¨ë„ (ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘) |
| `top_k` | 50 | Top-k ìƒ˜í”Œë§ |
| `top_p` | 0.95 | Nucleus ìƒ˜í”Œë§ |
| `creativity` | 0.5 | ì°½ì˜ì„± (0=ë³´ìˆ˜ì , 1=ë§¤ìš° ì°½ì˜ì ) |

## ğŸ”§ ë¬¸ì œ í•´ê²°

### CUDA Out of Memory

```yaml
# config.yaml
training:
  batch_size: 2  # 4ì—ì„œ 2ë¡œ ê°ì†Œ
  gradient_accumulation_steps: 8  # 4ì—ì„œ 8ë¡œ ì¦ê°€
```

### í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼

```yaml
# ì‘ì€ ëª¨ë¸ ì‚¬ìš©
model:
  size: "small"  # base ëŒ€ì‹ 

# ë°ì´í„° ì›Œì»¤ ì¦ê°€
data:
  num_workers: 8  # 4ì—ì„œ 8ë¡œ
```

### ìƒì„± í’ˆì§ˆì´ ë‚®ìŒ

```python
# Temperature ì¡°ì •
generator.generate_continuation(
    ...,
    temperature=0.9,  # 1.0ì—ì„œ ë‚®ì¶¤ (ë” ë³´ìˆ˜ì )
    top_k=40,         # 50ì—ì„œ ë‚®ì¶¤
)

# ë˜ëŠ” ë” ë§ì€ ì—í­ í•™ìŠµ
```

## ğŸ“Š ëª¨ë¸ í¬ê¸°

| Size | Parameters | VRAM | í•™ìŠµ ì‹œê°„ (100 epoch) |
|------|-----------|------|----------------------|
| Small | 45M | 4GB | ~1ì¼ |
| Base | 110M | 8GB | ~3ì¼ |
| Large | 350M | 16GB | ~7ì¼ |

## ğŸ’¡ íŒ

1. **Art Tatum ìŠ¤íƒ€ì¼ í•™ìŠµ**:
   ```yaml
   data:
     pijama_dir: "data/pijama"
     artist_filter: "art tatum"
   ```

2. **ìŠ¤íƒ€ì¼ í˜¼í•©**:
   ```python
   style_a, _, _ = model.encode_style(tokens_a)
   style_b, _, _ = model.encode_style(tokens_b)
   mixed = 0.5 * style_a + 0.5 * style_b
   ```

3. **ì‹¤ì‹œê°„ ìƒì„±**:
   ```python
   # ì§§ì€ ì²­í¬ë¡œ ìƒì„±
   for i in range(10):
       chunk = generator.generate_continuation(
           prompt_midi=last_output,
           num_tokens=64  # 512 ëŒ€ì‹ 
       )
   ```

## ğŸ†˜ ë„ì›€ë§

- **Documentation**: [docs/tatumflow_architecture.md](docs/tatumflow_architecture.md)
- **Model Analysis**: [docs/model_analysis.md](docs/model_analysis.md)
- **Issues**: https://github.com/ohhalim/fine_tuning_art-tatum_midi_solo/issues

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

í•™ìŠµ ì „:
- [ ] PyTorch ì„¤ì¹˜ í™•ì¸ (`python -c "import torch; print(torch.__version__)"`)
- [ ] CUDA ì‚¬ìš© ê°€ëŠ¥ í™•ì¸ (`python -c "import torch; print(torch.cuda.is_available())"`)
- [ ] MIDI ë°ì´í„° ì¤€ë¹„ (`data/midi/` í´ë”ì— `.mid` íŒŒì¼)
- [ ] `config.yaml` ì„¤ì • í™•ì¸

ìƒì„± ì „:
- [ ] ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (`checkpoints/best.pt` ì¡´ì¬)
- [ ] ì…ë ¥ MIDI íŒŒì¼ ì¤€ë¹„
- [ ] ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±

---

**Happy Improvising! ğŸ¹ğŸµ**
