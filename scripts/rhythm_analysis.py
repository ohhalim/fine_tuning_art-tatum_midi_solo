"""
Rhythm Analysis (ë¦¬ë“¬ ë¶„ì„) ìŠ¤í¬ë¦½íŠ¸

ì¬ì¦ˆì˜ í•µì‹¬ì¸ ë¦¬ë“¬ ë³µì¡ë„ì™€ ì‹±ì½”í˜ì´ì…˜ì„ ì¸¡ì •í•´.

ì¸¡ì • í•­ëª©:
- Tempo (BPM)
- Beat Strength (ë¹„íŠ¸ ê°•ë„)
- Syncopation Score (ì‹±ì½”í˜ì´ì…˜ ì ìˆ˜)
- Onset Density (ìŒí‘œ ë°€ë„)

ì‚¬ìš©ë²•:
    python scripts/rhythm_analysis.py \
        --generated_dir ./generated_audio \
        --reference_dir ./reference_jazz
"""

import argparse
import numpy as np
import librosa
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, List, Tuple


def analyze_rhythm(audio_path: str, sr: int = 22050) -> Dict[str, float]:
    """
    ë‹¨ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ë¦¬ë“¬ íŠ¹ì§• ë¶„ì„

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸

    Returns:
        ë¦¬ë“¬ íŠ¹ì§• ë”•ì…”ë„ˆë¦¬
    """
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, _ = librosa.load(audio_path, sr=sr)

    # 1. Tempo ì¶”ì •
    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)

    # 2. Onset Detection (ìŒí‘œ ì‹œì‘ì )
    onset_env = librosa.onset.onset_strength(y=y, sr=sr)
    onset_frames = librosa.onset.onset_detect(
        onset_envelope=onset_env,
        sr=sr,
        backtrack=True
    )

    # 3. Onset Density (ìŒí‘œ ë°€ë„: ì´ˆë‹¹ ìŒí‘œ ìˆ˜)
    duration = librosa.get_duration(y=y, sr=sr)
    onset_density = len(onset_frames) / duration if duration > 0 else 0

    # 4. Beat Strength (ë¹„íŠ¸ ê°•ë„)
    beat_strength = np.mean(onset_env)

    # 5. Syncopation Score (ì‹±ì½”í˜ì´ì…˜ ì ìˆ˜)
    # ë°•ìì™€ onsetì´ ì–¼ë§ˆë‚˜ ì–´ê¸‹ë‚˜ëŠ”ì§€ ì¸¡ì •
    syncopation = calculate_syncopation(onset_frames, beat_frames, sr)

    # 6. Rhythmic Regularity (ë¦¬ë“¬ ê·œì¹™ì„±)
    # onset ê°„ê²©ì˜ í‘œì¤€í¸ì°¨ (ë‚®ì„ìˆ˜ë¡ ê·œì¹™ì )
    if len(onset_frames) > 1:
        onset_intervals = np.diff(onset_frames)
        rhythm_regularity = np.std(onset_intervals) / np.mean(onset_intervals) if np.mean(onset_intervals) > 0 else 0
    else:
        rhythm_regularity = 0

    return {
        'tempo': tempo,
        'onset_density': onset_density,
        'beat_strength': beat_strength,
        'syncopation': syncopation,
        'rhythm_regularity': rhythm_regularity,
        'total_onsets': len(onset_frames),
        'total_beats': len(beat_frames),
    }


def calculate_syncopation(onset_frames: np.ndarray, beat_frames: np.ndarray, sr: int) -> float:
    """
    Syncopation Score ê³„ì‚°

    ì¬ì¦ˆì˜ í•µì‹¬: ë°•ì(beat)ì™€ ìŒí‘œ ì‹œì‘(onset)ì´ ì–¼ë§ˆë‚˜ ì–´ê¸‹ë‚˜ëŠ”ì§€

    Args:
        onset_frames: ìŒí‘œ ì‹œì‘ í”„ë ˆì„
        beat_frames: ë¹„íŠ¸ í”„ë ˆì„
        sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸

    Returns:
        Syncopation score (0~1, ë†’ì„ìˆ˜ë¡ ì‹±ì½”í˜ì´ì…˜ ë§ìŒ)
    """
    if len(onset_frames) == 0 or len(beat_frames) == 0:
        return 0.0

    # ê° onsetì´ ê°€ì¥ ê°€ê¹Œìš´ beatë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì¸¡ì •
    offsets = []

    for onset in onset_frames:
        # ê°€ì¥ ê°€ê¹Œìš´ beat ì°¾ê¸°
        distances = np.abs(beat_frames - onset)
        min_distance = np.min(distances)

        # ê°€ì¥ ê°€ê¹Œìš´ beat ê°„ê²©ìœ¼ë¡œ ì •ê·œí™”
        closest_beat_idx = np.argmin(distances)

        if closest_beat_idx < len(beat_frames) - 1:
            beat_interval = beat_frames[closest_beat_idx + 1] - beat_frames[closest_beat_idx]
        elif closest_beat_idx > 0:
            beat_interval = beat_frames[closest_beat_idx] - beat_frames[closest_beat_idx - 1]
        else:
            beat_interval = 1

        # ì •ê·œí™”ëœ offset (0 = beatì™€ ì •í™•íˆ ì¼ì¹˜, 0.5 = beat ì¤‘ê°„)
        normalized_offset = min_distance / beat_interval if beat_interval > 0 else 0

        offsets.append(normalized_offset)

    # Syncopation score: offsetì˜ í‰ê· 
    # 0ì— ê°€ê¹Œìš°ë©´ = beatì™€ ì •í™•íˆ ë§ìŒ (í´ë˜ì‹ì )
    # 0.3-0.5ì— ê°€ê¹Œìš°ë©´ = beat ì‚¬ì´ì— ë§ì´ ì¹¨ (ì¬ì¦ˆì )
    syncopation_score = np.mean(offsets)

    return syncopation_score


def analyze_directory_rhythm(directory: str, label: str = "Audio") -> Dict[str, List[float]]:
    """
    í´ë” ë‚´ ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ë¦¬ë“¬ ë¶„ì„

    Args:
        directory: ì˜¤ë””ì˜¤ í´ë”
        label: ë¼ë²¨

    Returns:
        ì „ì²´ ë¦¬ë“¬ íŠ¹ì§• ë”•ì…”ë„ˆë¦¬
    """
    print(f"\nğŸ“‚ {label} ë¦¬ë“¬ ë¶„ì„ ì¤‘...")

    directory = Path(directory)
    all_features = {
        'tempo': [],
        'onset_density': [],
        'beat_strength': [],
        'syncopation': [],
        'rhythm_regularity': [],
    }

    audio_files = []
    for ext in ['*.wav', '*.mp3', '*.flac']:
        audio_files.extend(directory.glob(ext))

    if not audio_files:
        print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {directory}")
        return all_features

    for i, audio_path in enumerate(audio_files):
        try:
            features = analyze_rhythm(str(audio_path))

            for key in all_features.keys():
                all_features[key].append(features[key])

            print(f"   âœ… {i+1}/{len(audio_files)}: {audio_path.name}")

        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {audio_path.name} - {e}")

    return all_features


def compare_rhythm_features(generated: Dict, reference: Dict) -> None:
    """
    ë¦¬ë“¬ íŠ¹ì§• ë¹„êµ

    Args:
        generated: ìƒì„± ì˜¤ë””ì˜¤ ë¦¬ë“¬ íŠ¹ì§•
        reference: ë ˆí¼ëŸ°ìŠ¤ ì˜¤ë””ì˜¤ ë¦¬ë“¬ íŠ¹ì§•
    """
    print(f"\n" + "=" * 80)
    print(f"ğŸ¥ ë¦¬ë“¬ íŠ¹ì§• ë¹„êµ")
    print("=" * 80)

    feature_names = {
        'tempo': 'Tempo (BPM)',
        'onset_density': 'Onset Density (notes/sec)',
        'beat_strength': 'Beat Strength',
        'syncopation': 'Syncopation Score',
        'rhythm_regularity': 'Rhythm Regularity',
    }

    print(f"\n{'íŠ¹ì§•':<30} {'ìƒì„±':<15} {'ë ˆí¼ëŸ°ìŠ¤':<15} {'ìœ ì‚¬ë„':<10}")
    print("-" * 80)

    for key, name in feature_names.items():
        if key not in generated or not generated[key]:
            continue

        gen_mean = np.mean(generated[key])
        ref_mean = np.mean(reference[key]) if reference[key] else 0

        # ìœ ì‚¬ë„ ê³„ì‚°
        if ref_mean > 0:
            similarity = (1 - abs(gen_mean - ref_mean) / ref_mean) * 100
            similarity = max(0, min(100, similarity))
        else:
            similarity = 0

        # ìƒíƒœ ì•„ì´ì½˜
        if similarity >= 90:
            status = "âœ…"
        elif similarity >= 70:
            status = "ğŸŸ¡"
        else:
            status = "âŒ"

        print(f"{name:<30} {gen_mean:<15.2f} {ref_mean:<15.2f} {similarity:>5.1f}% {status}")

    print("-" * 80)

    # íŠ¹ë³„ ë¶„ì„: Syncopation
    if generated['syncopation'] and reference['syncopation']:
        gen_sync = np.mean(generated['syncopation'])
        ref_sync = np.mean(reference['syncopation'])

        print(f"\nğŸµ Syncopation (ì‹±ì½”í˜ì´ì…˜) ë¶„ì„:")
        print(f"   ìƒì„±: {gen_sync:.3f}")
        print(f"   ë ˆí¼ëŸ°ìŠ¤: {ref_sync:.3f}")

        if gen_sync >= 0.3 and gen_sync <= 0.5:
            print(f"   âœ… ì¬ì¦ˆë‹¤ìš´ ì‹±ì½”í˜ì´ì…˜! (0.3~0.5 ë²”ìœ„)")
        elif gen_sync < 0.3:
            print(f"   âš ï¸  ì‹±ì½”í˜ì´ì…˜ ë¶€ì¡± (ë„ˆë¬´ ê·œì¹™ì )")
        else:
            print(f"   âš ï¸  ì‹±ì½”í˜ì´ì…˜ ê³¼ë‹¤ (ë„ˆë¬´ ë¶ˆê·œì¹™)")


def plot_rhythm_comparison(generated: Dict, reference: Dict, output_path: str):
    """
    ë¦¬ë“¬ íŠ¹ì§• ë¹„êµ ê·¸ë˜í”„

    Args:
        generated: ìƒì„± ì˜¤ë””ì˜¤ ë¦¬ë“¬ íŠ¹ì§•
        reference: ë ˆí¼ëŸ°ìŠ¤ ì˜¤ë””ì˜¤ ë¦¬ë“¬ íŠ¹ì§•
        output_path: ì €ì¥ ê²½ë¡œ
    """
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    axes = axes.flatten()

    features_to_plot = [
        ('tempo', 'Tempo (BPM)', 'Speed'),
        ('onset_density', 'Onset Density', 'Notes per Second'),
        ('beat_strength', 'Beat Strength', 'Accent Intensity'),
        ('syncopation', 'Syncopation Score', 'Off-beat Playing'),
        ('rhythm_regularity', 'Rhythm Regularity', 'Timing Consistency'),
    ]

    for i, (key, title, subtitle) in enumerate(features_to_plot):
        ax = axes[i]

        gen_data = generated.get(key, [])
        ref_data = reference.get(key, [])

        if gen_data and ref_data:
            # ë°•ìŠ¤í”Œë¡¯
            bp = ax.boxplot(
                [gen_data, ref_data],
                labels=['Generated', 'Reference'],
                patch_artist=True,
                widths=0.6
            )

            bp['boxes'][0].set_facecolor('lightgreen')
            bp['boxes'][1].set_facecolor('lightyellow')

            ax.set_title(f"{title}\n({subtitle})", fontsize=11, fontweight='bold')
            ax.grid(True, alpha=0.3)

            # í‰ê· ê°’ í‘œì‹œ
            gen_mean = np.mean(gen_data)
            ref_mean = np.mean(ref_data)
            ax.axhline(gen_mean, color='green', linestyle='--', alpha=0.5, linewidth=1)
            ax.axhline(ref_mean, color='orange', linestyle='--', alpha=0.5, linewidth=1)

    # ë§ˆì§€ë§‰ subplot ì œê±°
    fig.delaxes(axes[-1])

    plt.tight_layout()
    plt.savefig(output_path, dpi=300)
    print(f"\nğŸ“Š ë¦¬ë“¬ ë¶„ì„ ê·¸ë˜í”„ ì €ì¥ë¨: {output_path}")


def evaluate_rhythm(generated_dir: str, reference_dir: str, output_dir: str = './evaluation'):
    """ì „ì²´ ë¦¬ë“¬ ë¶„ì„ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸ¥ Rhythm Analysis (ë¦¬ë“¬ ë¶„ì„) ì‹œì‘")
    print("=" * 80)

    # 1. ë¶„ì„
    generated_features = analyze_directory_rhythm(generated_dir, "ìƒì„± ì˜¤ë””ì˜¤")
    reference_features = analyze_directory_rhythm(reference_dir, "ë ˆí¼ëŸ°ìŠ¤ ì¬ì¦ˆ")

    if not generated_features['tempo'] or not reference_features['tempo']:
        print("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return

    # 2. ë¹„êµ
    compare_rhythm_features(generated_features, reference_features)

    # 3. ê·¸ë˜í”„ ìƒì„±
    Path(output_dir).mkdir(exist_ok=True)
    plot_rhythm_comparison(
        generated_features,
        reference_features,
        f"{output_dir}/rhythm_comparison.png"
    )

    # 4. ìµœì¢… íŒì •
    print(f"\n" + "=" * 80)
    print("ğŸ† ìµœì¢… íŒì •:")

    # Syncopation ê¸°ì¤€ í‰ê°€
    if generated_features['syncopation']:
        avg_sync = np.mean(generated_features['syncopation'])
        ref_sync = np.mean(reference_features['syncopation']) if reference_features['syncopation'] else 0

        print(f"   Syncopation Score: {avg_sync:.3f} (ë ˆí¼ëŸ°ìŠ¤: {ref_sync:.3f})")

        if 0.3 <= avg_sync <= 0.5:
            print(f"   âœ… ì¬ì¦ˆë‹¤ìš´ ë¦¬ë“¬ê°! ì‹±ì½”í˜ì´ì…˜ ì™„ë²½")
        elif 0.2 <= avg_sync < 0.3:
            print(f"   ğŸŸ¡ ì•½ê°„ ê·œì¹™ì . ë” ìŠ¤ìœ™ê° í•„ìš”")
        elif avg_sync < 0.2:
            print(f"   âŒ ë„ˆë¬´ ê·œì¹™ì . ì¬ì¦ˆ ëŠë‚Œ ë¶€ì¡±")
        else:
            print(f"   âš ï¸  ë„ˆë¬´ ë¶ˆê·œì¹™. ì¼ê´€ì„± í•„ìš”")

    print("=" * 80)


def main():
    parser = argparse.ArgumentParser(description="ë¦¬ë“¬ ë¶„ì„")
    parser.add_argument(
        '--generated_dir',
        type=str,
        required=True,
        help='ìƒì„±ëœ ì˜¤ë””ì˜¤ í´ë”'
    )
    parser.add_argument(
        '--reference_dir',
        type=str,
        required=True,
        help='ë ˆí¼ëŸ°ìŠ¤ ì¬ì¦ˆ ì˜¤ë””ì˜¤ í´ë”'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./evaluation',
        help='ê²°ê³¼ ì €ì¥ í´ë”'
    )

    args = parser.parse_args()

    evaluate_rhythm(args.generated_dir, args.reference_dir, args.output_dir)


if __name__ == '__main__':
    main()
