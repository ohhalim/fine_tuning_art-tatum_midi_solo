# Phase 2: ì†Œê·œëª¨ ì‹¤í—˜ ğŸ§ª

**ëª©í‘œ**: ì‘ì€ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ê²€ì¦í•˜ì—¬ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

**ì˜ˆìƒ ì‹œê°„**: 2-3ì¼
**ë‚œì´ë„**: â­â­â­â˜†â˜†

---

## ì™œ ì†Œê·œëª¨ ì‹¤í—˜ë¶€í„° í• ê¹Œìš”?

í° ëª¨ë¸ë¡œ ë°”ë¡œ í›ˆë ¨í•˜ë©´:
- âŒ ë²„ê·¸ ë°œê²¬ì´ ëŠ¦ìŒ (ìˆ˜ì¼ í›„ì— ë°œê²¬)
- âŒ GPU ë¹„ìš© ë‚­ë¹„ ($ìˆ˜ì‹­ â†’ ìˆ˜ë°±)
- âŒ ë””ë²„ê¹… ì–´ë ¤ì›€

ì‘ì€ ëª¨ë¸ë¡œ ë¨¼ì €:
- âœ… ë²„ê·¸ë¥¼ ë¹ ë¥´ê²Œ ë°œê²¬ (1ì‹œê°„ ì•ˆì—)
- âœ… ë¹„ìš© ê±°ì˜ ì•ˆë“¦ ($1-2)
- âœ… ë¹ ë¥¸ iteration

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ë¯¸ë‹ˆ ì„¤ì • íŒŒì¼ ìƒì„± (`config_mini.yaml`)
- [ ] 1ê°œ MIDIë¡œ ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸
- [ ] ì†ì‹¤ í•¨ìˆ˜ ì •ìƒ ì‘ë™ í™•ì¸
- [ ] ì²« ìƒì„± ìƒ˜í”Œ í™•ì¸
- [ ] ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ê²€ì¦

---

## 1. ë¯¸ë‹ˆ ì„¤ì • ìƒì„±

### config_mini.yaml

```yaml
# ì‘ì€ ëª¨ë¸ (ë¹ ë¥¸ ì‹¤í—˜ìš©)
model:
  vocab_size: 2048
  hidden_dim: 128      # ê¸°ë³¸ 512 â†’ 128
  latent_dim: 64       # ê¸°ë³¸ 256 â†’ 64
  num_layers: 2        # ê¸°ë³¸ 12 â†’ 2
  num_heads: 4         # ê¸°ë³¸ 8 â†’ 4
  max_seq_len: 512     # ê¸°ë³¸ 2048 â†’ 512

training:
  batch_size: 2        # ì‘ê²Œ
  epochs: 100          # ì˜¤ë²„í”¼íŒ… ëª©ì 
  learning_rate: 0.0003
  use_amp: false       # ë””ë²„ê¹… ìœ„í•´ FP32
  use_ema: false

data:
  train_dir: 'data/art_tatum_midi/single'  # 1ê°œ íŒŒì¼ë§Œ
  val_dir: 'data/art_tatum_midi/single'
  max_seq_len: 512

checkpoint:
  save_every: 10       # ìì£¼ ì €ì¥
  checkpoint_dir: 'checkpoints/mini'
```

---

## 2. 1ê°œ íŒŒì¼ë¡œ ì˜¤ë²„í”¼íŒ… í…ŒìŠ¤íŠ¸

### ì™œ ì˜¤ë²„í”¼íŒ…ì„ ì˜ë„ì ìœ¼ë¡œ?

**ì˜¤ë²„í”¼íŒ…ì´ ì•ˆë˜ë©´ â†’ ë­”ê°€ ì˜ëª»ë¨!**

ì •ìƒì ì¸ ëª¨ë¸ì´ë¼ë©´:
- 1ê°œ íŒŒì¼ì„ 100 epochs ë³´ë©´ â†’ ì™„ë²½íˆ ì™¸ì›Œì•¼ í•¨
- ì†ì‹¤ì´ ê±°ì˜ 0ìœ¼ë¡œ ë–¨ì–´ì ¸ì•¼ í•¨
- ì›ë³¸ê³¼ ê±°ì˜ ë˜‘ê°™ì´ ì¬ìƒì„±í•´ì•¼ í•¨

### ì‹¤í–‰

```bash
# 1ê°œ íŒŒì¼ë§Œ ë³µì‚¬
mkdir -p data/art_tatum_midi/single
cp data/art_tatum_midi/train/tiger_rag.mid data/art_tatum_midi/single/

# í›ˆë ¨ ì‹œì‘
python scripts/phase2_quick_test.py --config config_mini.yaml
```

### ì˜ˆìƒ ê²°ê³¼

```
Epoch 1/100: Loss=6.234
Epoch 10/100: Loss=4.123
Epoch 20/100: Loss=2.456
Epoch 50/100: Loss=0.892
Epoch 100/100: Loss=0.123  â† ë§¤ìš° ë‚®ì•„ì•¼ í•¨!
```

**ë§Œì•½ Lossê°€ ì•ˆ ë–¨ì–´ì§€ë©´**:
- Learning rate ë„ˆë¬´ ë‚®ìŒ â†’ ì˜¬ë¦¬ê¸°
- ëª¨ë¸ ë„ˆë¬´ ì‘ìŒ â†’ hidden_dim ëŠ˜ë¦¬ê¸°
- ë²„ê·¸ ìˆìŒ â†’ ì½”ë“œ ì²´í¬

---

## 3. ìƒì„± ìƒ˜í”Œ í™•ì¸

### ì²« ìƒì„±!

```bash
python scripts/generate_music.py \
  --checkpoint checkpoints/mini/epoch_100.pt \
  --config config_mini.yaml \
  --mode continuation \
  --input data/art_tatum_midi/single/tiger_rag.mid \
  --output outputs/first_generation.mid \
  --max_length 200
```

### ë“¤ì–´ë³´ê¸°

```bash
# MIDI â†’ MP3 ë³€í™˜
python scripts/phase5_midi_to_mp3.py \
  --input outputs/first_generation.mid \
  --output outputs/first_generation.mp3

# ì¬ìƒ
# Linux: mpg123 outputs/first_generation.mp3
# macOS: afplay outputs/first_generation.mp3
# Windows: start outputs/first_generation.mp3
```

### ê¸°ëŒ€ì¹˜

**ì¢‹ì€ ì‹ í˜¸**:
- âœ… ìŒì´ ë‚˜ì˜´ (ì¹¨ë¬µ ì•„ë‹˜)
- âœ… í”¼ì•„ë…¸ ì†Œë¦¬
- âœ… ì¼ë¶€ íŒ¨í„´ì´ ì›ë³¸ê³¼ ìœ ì‚¬

**ì´ ë‹¨ê³„ì—ì„œëŠ” ì™„ë²½í•  í•„ìš” ì—†ìŒ!**
- âš ï¸  ë°˜ë³µì´ ë§ì•„ë„ OK
- âš ï¸  ì¡°í™”ë¡­ì§€ ì•Šì•„ë„ OK
- âš ï¸  ì§§ì•„ë„ OK

**ì¤‘ìš”í•œ ê±´**: íŒŒì´í”„ë¼ì¸ì´ ì‘ë™í•œë‹¤ëŠ” ê²ƒ!

---

## 4. ì†ì‹¤ í•¨ìˆ˜ ë¶„ì„

### TensorBoardë¡œ í™•ì¸

```bash
tensorboard --logdir=logs/tensorboard/mini
```

**ì²´í¬ í•­ëª©**:

1. **Total Loss**: ê°ì†Œí•˜ëŠ”ê°€? (6.0 â†’ 0.1)
2. **Reconstruction Loss**: ê°€ì¥ ë¹ ë¥´ê²Œ ê°ì†Œ
3. **Diffusion Loss**: ì²œì²œíˆ ê°ì†Œ
4. **KL Loss**: ì‘ì€ ê°’ ìœ ì§€ (~0.01)
5. **Theory Loss**: ê°ì†Œ

**ì •ìƒ íŒ¨í„´**:
```
Total Loss: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\__________  (ê¸‰ê²©íˆ ê°ì†Œ)
Recon Loss: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\_________  (ë¹ ë¥´ê²Œ 0ìœ¼ë¡œ)
Diff Loss:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\______   (ì²œì²œíˆ ê°ì†Œ)
KL Loss:    â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚  (ë‚®ê²Œ ìœ ì§€)
```

**ë¹„ì •ìƒ íŒ¨í„´**:
```
Total Loss: â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚  â† ì•ˆ ë–¨ì–´ì§ (ë²„ê·¸!)
Total Loss: â–‚â–ˆâ–‚â–ˆâ–‚â–ˆâ–‚â–ˆâ–‚â–ˆâ–‚â–ˆâ–‚â–ˆ   â† ì§„ë™ (LR ë„ˆë¬´ ë†’ìŒ)
Total Loss: NaN                â† Gradient exploding
```

---

## 5. ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¬¸ì œ: Lossê°€ NaN

**ì›ì¸**: Gradient explosion

**í•´ê²°**:
```yaml
training:
  gradient_clip: 1.0  # ì¶”ê°€
  learning_rate: 0.0001  # ì¤„ì´ê¸°
```

### ë¬¸ì œ: Lossê°€ ì•ˆ ë–¨ì–´ì§

**ì›ì¸**: Learning rate ë„ˆë¬´ ë‚®ìŒ

**í•´ê²°**:
```yaml
training:
  learning_rate: 0.001  # ì˜¬ë¦¬ê¸°
```

### ë¬¸ì œ: ìƒì„±ì´ ë°˜ë³µë§Œ

**ì›ì¸**: ëª¨ë¸ì´ ë„ˆë¬´ ì‘ìŒ or ë°ì´í„° ë¶€ì¡±

**í•´ê²°**:
- ì •ìƒì…ë‹ˆë‹¤! Phase 2ëŠ” ê°œë… ì¦ëª…ìš©
- Phase 3ì—ì„œ í° ëª¨ë¸ ì‚¬ìš©í•˜ë©´ í•´ê²°ë¨

---

## ğŸ“ í•™ìŠµ ë‚´ìš©

### ì˜¤ë²„í”¼íŒ… vs ì–¸ë”í”¼íŒ…

**ì˜¤ë²„í”¼íŒ…**: í›ˆë ¨ ë°ì´í„°ë§Œ ì™¸ì›€ (ì•”ê¸°)
- í›ˆë ¨ Loss â†“, ê²€ì¦ Loss â†‘
- í•´ê²°: ë” ë§ì€ ë°ì´í„°, Dropout, Regularization

**ì–¸ë”í”¼íŒ…**: ì œëŒ€ë¡œ í•™ìŠµ ëª»í•¨
- í›ˆë ¨ Lossë„ ë†’ìŒ
- í•´ê²°: ëª¨ë¸ í‚¤ìš°ê¸°, ë” í›ˆë ¨

**Phase 2 ëª©í‘œ**: ì˜ë„ì  ì˜¤ë²„í”¼íŒ…ìœ¼ë¡œ ëª¨ë¸ ëŠ¥ë ¥ í™•ì¸

### Reconstruction Loss vs Diffusion Loss

**Reconstruction**: ì…ë ¥ â†’ ì¶œë ¥ ì¬êµ¬ì„±
- "ì´ ì•…ë³´ë¥¼ ë˜‘ê°™ì´ ë³µì‚¬í•´"
- ë¹ ë¥´ê²Œ í•™ìŠµë¨

**Diffusion**: ë…¸ì´ì¦ˆ â†’ ìŒì•…
- "ë…¸ì´ì¦ˆì—ì„œ ìŒì•…ì„ ë§Œë“¤ì–´"
- ëŠë¦¬ê²Œ í•™ìŠµë¨

ë‘˜ ë‹¤ ì¤‘ìš”!

### Checkpoint ì €ì¥ ì „ëµ

**ë„ˆë¬´ ìì£¼**: ë””ìŠ¤í¬ ê³µê°„ ë‚­ë¹„
**ë„ˆë¬´ ì ê²Œ**: ì¢‹ì€ ëª¨ë¸ ë†“ì¹¨

**ê¶Œì¥**:
- Phase 2: 10 epochsë§ˆë‹¤
- Phase 3: 1000 stepsë§ˆë‹¤

---

## âœ… Phase 2 ì™„ë£Œ ì²´í¬

- [ ] 1ê°œ íŒŒì¼ë¡œ Loss < 0.5 ë‹¬ì„±
- [ ] ì²« ìƒì„± ìƒ˜í”Œì´ ìŒì„ ëƒ„
- [ ] TensorBoardì—ì„œ Loss ê°ì†Œ í™•ì¸
- [ ] ì²´í¬í¬ì¸íŠ¸ ì €ì¥/ë¡œë“œ ì‘ë™
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´í•´í•¨

---

## ë‹¤ìŒ ë‹¨ê³„

**Phase 3: ë³¸ê²© í›ˆë ¨**ìœ¼ë¡œ ì´ë™:
```bash
cat docs/phase3_training.md
```

**ì¶•í•˜í•©ë‹ˆë‹¤! ì´ì œ ì§„ì§œ í›ˆë ¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€**
