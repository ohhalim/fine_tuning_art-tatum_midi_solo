# MIDI Fine-tuning ì‹¤ì „ ê°€ì´ë“œ

**"ì–´ë–»ê²Œ MIDI ë°ì´í„°ë¡œ AIë¥¼ í•™ìŠµì‹œì¼œì„œ ë‚´ê°€ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì˜ ìŒì•…ì„ ë§Œë“¤ê¹Œ?"**

ì´ë¡  ë…¼ë¬¸ì€ ê±´ë„ˆë›°ê³ , **ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€** ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ¯ í•µì‹¬ ì§ˆë¬¸

1. **MIDI íŒŒì¼ì„ AIê°€ ì–´ë–»ê²Œ ì´í•´í•˜ë‚˜?** â†’ Tokenization
2. **Fine-tuningì€ ì •í™•íˆ ë­˜ í•˜ëŠ” ê±°ì•¼?** â†’ ëª¨ë¸ì´ ìŠ¤íƒ€ì¼ í•™ìŠµ
3. **Brad Mehldau ìŠ¤íƒ€ì¼ì„ ë§Œë“¤ë ¤ë©´?** â†’ ê·¸ì˜ MIDI ë°ì´í„°ë¡œ í•™ìŠµ
4. **ì–¼ë§ˆë‚˜ ë°ì´í„°ê°€ í•„ìš”í•´?** â†’ ìµœì†Œ 50ê°œ, ì´ìƒì ìœ¼ë¡œëŠ” 200ê°œ+ MIDI
5. **ë‚´ ì»´í“¨í„°ë¡œ ê°€ëŠ¥í•´?** â†’ RTX 3060 (8GB)ì´ë©´ ì¶©ë¶„

---

## ğŸ“Š ì „ì²´ ì›Œí¬í”Œë¡œìš° (í•œëˆˆì— ë³´ê¸°)

```
1. MIDI íŒŒì¼ ìˆ˜ì§‘
   â†“
2. Tokenization (MIDI â†’ ìˆ«ì í† í°)
   â†“
3. Dataset ì¤€ë¹„ (HuggingFace Dataset)
   â†“
4. Pre-trained ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì„ íƒì‚¬í•­)
   â†“
5. Fine-tuning (QLoRA ì‚¬ìš©)
   â†“
6. Generate (ìƒˆë¡œìš´ MIDI ìƒì„±)
   â†“
7. MIDI â†’ ìŒì•… (FL Studio ë“±ì—ì„œ ì¬ìƒ)
```

**ì†Œìš” ì‹œê°„**:
- ë°ì´í„° ì¤€ë¹„: 1-2ì‹œê°„
- Fine-tuning: 2-6ì‹œê°„ (GPUì— ë”°ë¼)
- ìƒì„±: ëª‡ ì´ˆ

---

## 1ï¸âƒ£ MIDIë¥¼ AIê°€ ì´í•´í•˜ëŠ” ë°©ë²• (Tokenization)

### MIDI íŒŒì¼ì´ë€?

MIDIëŠ” **ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤**ì…ë‹ˆë‹¤:

```
Time    Event
0.0s    Note ON:  C4 (pitch=60, velocity=80)
0.5s    Note OFF: C4
0.5s    Note ON:  E4 (pitch=64, velocity=75)
1.0s    Note OFF: E4
1.0s    Note ON:  G4 (pitch=67, velocity=80)
1.5s    Note OFF: G4
```

### AIëŠ” ìˆ«ìë§Œ ì´í•´í•¨

MIDI ì´ë²¤íŠ¸ë¥¼ **í† í°(ìˆ«ì)**ìœ¼ë¡œ ë³€í™˜:

```
ì›ë³¸ MIDI:
  Note ON C4, velocity 80

Tokenization í›„:
  [BOS, NOTE_ON_60, VELOCITY_80, TIME_SHIFT_500, NOTE_OFF_60, ...]
  â†“
  [1, 63, 338, 259, 191, ...]  (ì‹¤ì œ ìˆ«ì í† í°)
```

ì´ì œ AIê°€ ì´í•´ ê°€ëŠ¥! (ì–¸ì–´ ëª¨ë¸ì´ ë‹¨ì–´ë¥¼ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ê²ƒê³¼ ë™ì¼)

### ì¸ê¸°ìˆëŠ” Tokenization ë°©ë²•

#### 1. **REMI (ìš°ë¦¬ í”„ë¡œì íŠ¸ ì‚¬ìš©)**

```python
from miditok import REMI

# Tokenizer ìƒì„±
tokenizer = REMI()

# MIDI â†’ í† í°
tokens = tokenizer("brad_mehldau_solo.mid")
# ê²°ê³¼: [1, 63, 338, 259, 191, 63, 340, ...]

# í† í° â†’ MIDI
midi = tokenizer.tokens_to_midi(tokens)
midi.write("output.mid")
```

**REMI í† í° ì¢…ë¥˜:**
- `BAR`: ë§ˆë”” êµ¬ë¶„
- `POSITION`: ë§ˆë”” ë‚´ ìœ„ì¹˜ (1/16 ë‹¨ìœ„)
- `NOTE_ON_X`: X ìŒë†’ì´ ë…¸íŠ¸ ì‹œì‘
- `NOTE_OFF`: ë…¸íŠ¸ ë
- `VELOCITY_X`: ì„¸ê¸° (0-127)
- `TEMPO_X`: í…œí¬ (BPM)

#### 2. **Event-based (ê°„ë‹¨í•¨)**

```python
# ìš°ë¦¬ í”„ë¡œì íŠ¸ êµ¬í˜„
tokens = [
    BOS,              # ì‹œì‘
    NOTE_ON_60,       # C4 ì¼œê¸°
    TIME_SHIFT_500,   # 500ms ëŒ€ê¸°
    NOTE_OFF_60,      # C4 ë„ê¸°
    NOTE_ON_64,       # E4 ì¼œê¸°
    TIME_SHIFT_500,
    NOTE_OFF_64,
    EOS               # ë
]
```

### ì‹¤ì œ ì½”ë“œ ì˜ˆì‹œ

```python
# Production Transformer ë¸Œëœì¹˜ì—ì„œ
from data.event_tokenizer import EventTokenizer

tokenizer = EventTokenizer()

# 1. MIDI íŒŒì¼ â†’ í† í°
tokens = tokenizer.encode("brad_mehldau_solo.mid")
print(tokens)  # [1, 63, 338, 259, ...]

# 2. í† í° â†’ MIDI íŒŒì¼
events = tokenizer.decode(tokens)
midi = tokenizer.events_to_midi(events, "output.mid")
```

**í•µì‹¬**: MIDI ì´ë²¤íŠ¸ë¥¼ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì ì‹œí€€ìŠ¤ë¡œ ë³€í™˜!

---

## 2ï¸âƒ£ Fine-tuningì´ ì •í™•íˆ ë­˜ í•˜ëŠ”ê°€?

### Pre-training vs Fine-tuning

#### Pre-training (ì‚¬ì „ í•™ìŠµ)
- **ëª©ì **: ì¼ë°˜ì ì¸ ìŒì•… íŒ¨í„´ í•™ìŠµ
- **ë°ì´í„°**: ìˆ˜ë§Œ ê°œì˜ ë‹¤ì–‘í•œ MIDI (í´ë˜ì‹, ì¬ì¦ˆ, íŒ ë“±)
- **ê²°ê³¼**: "ìŒì•…ì´ë€ ì´ëŸ° ê±°êµ¬ë‚˜" ì´í•´

```
Input:  [C, E, G]
Output: [C, E, G, C]  (ì½”ë“œ ì§„í–‰ ì˜ˆì¸¡)
```

#### Fine-tuning (ë¯¸ì„¸ ì¡°ì •)
- **ëª©ì **: íŠ¹ì • ìŠ¤íƒ€ì¼ í•™ìŠµ (Brad Mehldau ìŠ¤íƒ€ì¼)
- **ë°ì´í„°**: Brad Mehldau MIDIë§Œ 50-200ê°œ
- **ê²°ê³¼**: "Brad MehldauëŠ” ì´ë ‡ê²Œ ì—°ì£¼í•˜ëŠ”êµ¬ë‚˜" í•™ìŠµ

```
Input:  [Cmaj7, Am7]
Output: [complex_brad_mehldau_voicing, rhythmic_pattern, ...]
```

### ë¹„ìœ 

**Pre-training**: í•œêµ­ì–´ ë¬¸ë²•ê³¼ ì¼ë°˜ ì§€ì‹ í•™ìŠµ
- "ë‚˜ëŠ” í•™ìƒì…ë‹ˆë‹¤", "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë‹¤" ë“±

**Fine-tuning**: íŠ¹ì • ì‘ê°€ ìŠ¤íƒ€ì¼ í•™ìŠµ
- í•œê°• ì‘ê°€ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì“°ê¸°
- ê¹€í›ˆ ì‘ê°€ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì“°ê¸°

### Fine-tuningì´ í•™ìŠµí•˜ëŠ” ê²ƒë“¤

Brad Mehldau MIDIë¡œ fine-tuningí•˜ë©´:

1. **Harmony (í™”ìŒ)**
   - ê·¸ê°€ ìì£¼ ì“°ëŠ” voicing
   - í…ì…˜ ë…¸íŠ¸ ì‚¬ìš©ë²•
   - ì½”ë“œ ì§„í–‰ íŒ¨í„´

2. **Rhythm (ë¦¬ë“¬)**
   - ë…íŠ¹í•œ íƒ€ì´ë°
   - Syncopation (ì‹±ì½”í˜ì´ì…˜)
   - Rubato (í…œí¬ ë³€í™”)

3. **Melody (ë©œë¡œë””)**
   - í”„ë ˆì´ì§•
   - ìŒì—­ ì‚¬ìš©
   - ìŒì • ì´ë™ íŒ¨í„´

4. **Dynamics (ë‹¤ì´ë‚˜ë¯¹)**
   - Velocity íŒ¨í„´
   - Crescendo/Diminuendo

### QLoRA Fine-tuning

ìš°ë¦¬ í”„ë¡œì íŠ¸ëŠ” **QLoRA** ì‚¬ìš©:

```python
# Base modelì˜ 99%ëŠ” freeze (ê³ ì •)
# 1%ë§Œ í•™ìŠµ (LoRA adapters)

Base Model (150M params): â„ï¸ Frozen
   â†“
LoRA Adapters (2.8M params): ğŸ”¥ Training
   â†“
Brad Mehldau style learned!
```

**ì¥ì **:
- ë©”ëª¨ë¦¬ 75% ì ˆì•½
- í•™ìŠµ ì‹œê°„ 50% ë‹¨ì¶•
- ì„±ëŠ¥ì€ ê±°ì˜ ë™ì¼

---

## 3ï¸âƒ£ ì‹¤ì œ ì½”ë“œë¡œ ë³´ëŠ” Fine-tuning

### Step 1: ë°ì´í„° ì¤€ë¹„

```python
# 1. Brad Mehldau MIDI íŒŒì¼ ëª¨ìœ¼ê¸°
data/brad_mehldau/
  â”œâ”€â”€ solo_1.mid
  â”œâ”€â”€ solo_2.mid
  â”œâ”€â”€ ...
  â””â”€â”€ solo_50.mid

# 2. Tokenization & Dataset ìƒì„±
from data.midi_dataset import create_dataset_from_midi_files
from data.event_tokenizer import EventTokenizer

tokenizer = EventTokenizer()

dataset = create_dataset_from_midi_files(
    midi_dir="data/brad_mehldau",
    tokenizer=tokenizer,
    max_seq_len=2048,
    train_split=0.8  # 80% í•™ìŠµ, 20% ê²€ì¦
)

# ê²°ê³¼:
# dataset['train']: 40ê°œ MIDI â†’ 40,000ê°œ í† í° ì‹œí€€ìŠ¤
# dataset['validation']: 10ê°œ MIDI
```

### Step 2: ëª¨ë¸ & QLoRA ì„¤ì •

```python
from models import MusicTransformerForGeneration
from models.qlora import QLoRAConfig, apply_qlora_to_model

# 1. Base model ë¶ˆëŸ¬ì˜¤ê¸° (ë˜ëŠ” ìƒˆë¡œ ìƒì„±)
model = MusicTransformerForGeneration.from_pretrained(
    "pretrained_music_transformer",  # ì„ íƒì‚¬í•­
    quantization_config=bnb_config   # 4-bit quantization
)

# 2. QLoRA ì ìš©
qlora_config = QLoRAConfig(
    lora_rank=8,        # ë‚®ì„ìˆ˜ë¡ íš¨ìœ¨ì , ë†’ì„ìˆ˜ë¡ í‘œí˜„ë ¥
    lora_alpha=16,      # LoRA scaling
    lora_dropout=0.1    # Overfitting ë°©ì§€
)

model = apply_qlora_to_model(model, qlora_config)

# ì¶œë ¥:
# Total parameters: 150,000,000
# Trainable parameters: 2,800,000 (1.9%)
# âœ… 99%ëŠ” frozen, 1%ë§Œ í•™ìŠµ!
```

### Step 3: Fine-tuning ì‹¤í–‰

```python
from transformers import Trainer, TrainingArguments

# Training ì„¤ì •
training_args = TrainingArguments(
    output_dir="experiments/brad_mehldau_v1",

    # Batch & Epochs
    per_device_train_batch_size=4,    # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼
    gradient_accumulation_steps=4,    # Effective batch = 16
    num_train_epochs=5,                # ë³´í†µ 5-10 epochs

    # Learning rate
    learning_rate=3e-4,                # LoRAëŠ” ë†’ì€ LR ì‚¬ìš©
    warmup_steps=100,

    # íš¨ìœ¨ì„±
    fp16=True,                         # Mixed precision

    # Logging
    logging_steps=10,
    eval_steps=100,
    save_steps=500,

    # W&B (Weights & Biases)
    report_to="wandb"                  # ì‹¤í—˜ ì¶”ì 
)

# Trainer ìƒì„±
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset['train'],
    eval_dataset=dataset['validation']
)

# ğŸš€ í•™ìŠµ ì‹œì‘!
trainer.train()

# ì§„í–‰ ìƒí™©:
# Epoch 1/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [10:23<00:00]
# Loss: 2.456 â†’ 1.823 â†’ 1.234 (ì¢‹ì•„ì§€ê³  ìˆìŒ!)
```

### Step 4: ìƒì„± (Generate)

```python
from inference.generator import MusicGenerator

# 1. Fine-tuned ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
generator = MusicGenerator("experiments/brad_mehldau_v1/final_model")

# 2. ì½”ë“œ ì§„í–‰ ì œê³µ
prompt = "Cmaj7 Am7 Dm7 G7"  # ii-V-I in C

# 3. ìƒì„±!
generator.generate_and_save(
    prompt=prompt,
    output_path="brad_mehldau_solo.mid",
    max_length=512,      # í† í° ìˆ˜ (ì•½ 30ì´ˆ ìŒì•…)
    temperature=0.9,     # 0.7-1.0: ì•ˆì •ì , 1.0-1.5: ì°½ì˜ì 
    top_p=0.95          # Nucleus sampling
)

# ê²°ê³¼: brad_mehldau_solo.mid ìƒì„±!
```

### Step 5: FL Studioì—ì„œ ì¬ìƒ

```
1. FL Studio ì‹¤í–‰
2. File â†’ Import â†’ MIDI file
3. brad_mehldau_solo.mid ì„ íƒ
4. í”¼ì•„ë…¸ VST ì„ íƒ (ì˜ˆ: Keyscape, Addictive Keys)
5. ì¬ìƒ â–¶ï¸
```

---

## 4ï¸âƒ£ ì‹¤ì œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ê°€?

### Training ì¤‘ ëª¨ë¸ ë‚´ë¶€

```python
# Epoch 1, Step 1
Input:  [BOS, Cmaj7, NOTE_ON_60, ...]
Target: [Cmaj7, NOTE_ON_60, TIME_SHIFT_100, ...]

Model prediction: [Cmaj7, NOTE_ON_62, ...]  âŒ í‹€ë¦¼
Loss: 2.5 (ë†’ìŒ)
â†’ LoRA weights ì—…ë°ì´íŠ¸

# Epoch 1, Step 100
Input:  [BOS, Cmaj7, NOTE_ON_60, ...]
Target: [Cmaj7, NOTE_ON_60, TIME_SHIFT_100, ...]

Model prediction: [Cmaj7, NOTE_ON_60, ...]  âœ… ë§ìŒ!
Loss: 1.8 (ë‚®ì•„ì§)

# Epoch 5, Step 5000
Loss: 0.8 (ë§¤ìš° ë‚®ìŒ)
â†’ Brad Mehldau ìŠ¤íƒ€ì¼ í•™ìŠµ ì™„ë£Œ!
```

### Generation ì¤‘ ëª¨ë¸ ë‚´ë¶€

```python
# ì‚¬ìš©ì ì…ë ¥: "Cmaj7 Am7 Dm7 G7"

# Step 1: ì‹œì‘ í† í°
generated = [BOS, CHORD_Cmaj7]

# Step 2: ë‹¤ìŒ í† í° ì˜ˆì¸¡
logits = model(generated)
# logits: [0.01, 0.05, 0.8, 0.1, ...]  (ê° í† í°ì˜ í™•ë¥ )

# Temperatureë¡œ ì¡°ì •
probs = softmax(logits / temperature)

# Top-p samplingìœ¼ë¡œ ì„ íƒ
next_token = sample(probs, top_p=0.95)  # NOTE_ON_60

generated = [BOS, CHORD_Cmaj7, NOTE_ON_60]

# Step 3-512: ë°˜ë³µ
# ìµœì¢…: [BOS, CHORD_Cmaj7, NOTE_ON_60, TIME_SHIFT_100, ...]
```

---

## 5ï¸âƒ£ ì–¼ë§ˆë‚˜ ë°ì´í„°ê°€ í•„ìš”í•œê°€?

### ìµœì†Œ ìš”êµ¬ì‚¬í•­

```
50ê°œ MIDI íŒŒì¼ (ê° 1-3ë¶„)
= ì•½ 50-150ë¶„ ìŒì•…
= ì¶©ë¶„íˆ í•™ìŠµ ê°€ëŠ¥
```

### ì´ìƒì ì¸ ì–‘

```
200+ MIDI íŒŒì¼
= 200-600ë¶„ ìŒì•…
= ê³ í’ˆì§ˆ ê²°ê³¼
```

### Data Augmentationìœ¼ë¡œ ëŠ˜ë¦¬ê¸°

ì›ë³¸: 50ê°œ MIDI
â†“
**Transposition** (12 keys):
50 Ã— 12 = 600ê°œ

**Tempo variation** (3 speeds: 0.9x, 1.0x, 1.1x):
600 Ã— 3 = 1,800ê°œ

**ìµœì¢…**: 1,800ê°œ í•™ìŠµ ìƒ˜í”Œ!

```python
# ìë™ augmentation
dataset = create_dataset_from_midi_files(
    midi_dir="data/brad_mehldau",
    tokenizer=tokenizer,
    augment=True  # ìë™ìœ¼ë¡œ 12Ã—3 = 36ë°° ì¦ê°€!
)
```

---

## 6ï¸âƒ£ ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: Brad Mehldau ìŠ¤íƒ€ì¼ ì†”ë¡œ ìƒì„±

```bash
# 1. ë°ì´í„° ì¤€ë¹„ (50ê°œ MIDI ìˆ˜ì§‘)
# 2. Fine-tuning
python training/train.py \
    --data_dir data/brad_mehldau \
    --output_dir experiments/brad_v1 \
    --num_train_epochs 5 \
    --use_qlora

# ì‹œê°„: 3-6ì‹œê°„ (RTX 3060)

# 3. ìƒì„±
python inference/generator.py \
    --checkpoint experiments/brad_v1/final_model \
    --prompt "Fmaj7 Dm7 Gm7 C7" \
    --output solo.mid

# ì‹œê°„: 5ì´ˆ

# 4. FL Studioì—ì„œ ì¬ìƒ!
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì—¬ëŸ¬ ë²„ì „ ìƒì„± & ì„ íƒ

```python
# 5ê°œ ë²„ì „ ìƒì„±
for i in range(5):
    generator.generate_and_save(
        prompt="Cmaj7 Am7 Dm7 G7",
        output_path=f"solo_v{i+1}.mid",
        temperature=0.8 + i*0.1  # ë‹¤ì–‘ì„±
    )

# ê²°ê³¼:
# solo_v1.mid (temperature=0.8, ì•ˆì •ì )
# solo_v2.mid (temperature=0.9, ê· í˜•)
# solo_v3.mid (temperature=1.0, ì°½ì˜ì )
# solo_v4.mid (temperature=1.1, ì‹¤í—˜ì )
# solo_v5.mid (temperature=1.2, ë¬´ì‘ìœ„)

# â†’ ê°€ì¥ ë§ˆìŒì— ë“œëŠ” ê²ƒ ì„ íƒ!
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë‚´ ë©œë¡œë””ì— ë°˜ì£¼ ì¶”ê°€

```python
# 1. ë‚´ê°€ ë§Œë“  ë©œë¡œë”” MIDI
my_melody = "data/my_melody.mid"

# 2. ì½”ë“œ ì§„í–‰ ì¶”ì¶œ
chords = extract_chords(my_melody)  # ["Cmaj7", "Am7", ...]

# 3. Brad Mehldau ìŠ¤íƒ€ì¼ ë°˜ì£¼ ìƒì„±
generator.generate_and_save(
    prompt=" ".join(chords),
    output_path="accompaniment.mid"
)

# 4. FL Studioì—ì„œ í•©ì¹˜ê¸°
# Track 1: my_melody.mid
# Track 2: accompaniment.mid
```

---

## 7ï¸âƒ£ ì„±ëŠ¥ ìµœì í™” & íŒ

### Temperature ì„ íƒ

```python
temperature = 0.7  # ë§¤ìš° ì•ˆì •ì , ë°˜ë³µì 
temperature = 0.9  # ì¶”ì²œ! ì•ˆì • + ì°½ì˜ì„±
temperature = 1.0  # ê¸°ë³¸ê°’
temperature = 1.2  # ì‹¤í—˜ì , ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥
temperature = 1.5  # ê±°ì˜ ë¬´ì‘ìœ„
```

**ì‹¤í—˜ ë°©ë²•**:
1. 0.8-1.2 ì‚¬ì´ì—ì„œ 5ê°œ ìƒì„±
2. ê°€ì¥ ì¢‹ì€ ê²ƒ ì„ íƒ
3. ê·¸ temperature ì‚¬ìš©

### Fine-tuning Hyperparameters

```yaml
# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (1ì‹œê°„)
num_train_epochs: 3
batch_size: 8
learning_rate: 5e-4

# ê· í˜• (3-6ì‹œê°„)
num_train_epochs: 5
batch_size: 4
learning_rate: 3e-4

# ìµœê³  í’ˆì§ˆ (12+ ì‹œê°„)
num_train_epochs: 10
batch_size: 2
learning_rate: 2e-4
```

### LoRA Rank ì„ íƒ

```python
lora_rank = 4   # ë¹ ë¦„, ë©”ëª¨ë¦¬ ì ìŒ, í‘œí˜„ë ¥ ë‚®ìŒ
lora_rank = 8   # ì¶”ì²œ! ê· í˜•ì¡í˜
lora_rank = 16  # ëŠë¦¼, ë©”ëª¨ë¦¬ ë§ìŒ, í‘œí˜„ë ¥ ë†’ìŒ
lora_rank = 32  # ê±°ì˜ full fine-tuning
```

---

## 8ï¸âƒ£ ë¬¸ì œ í•´ê²° (Troubleshooting)

### Q: ìƒì„±ëœ ìŒì•…ì´ ì´ìƒí•´ìš” (ë¬´ì‘ìœ„)

**ì›ì¸**: Under-training ë˜ëŠ” temperature ë„ˆë¬´ ë†’ìŒ

**í•´ê²°**:
1. Training loss í™•ì¸: >1.5ì´ë©´ ë” í•™ìŠµ í•„ìš”
2. Temperature ë‚®ì¶”ê¸°: 0.9 â†’ 0.7
3. Epochs ëŠ˜ë¦¬ê¸°: 5 â†’ 10

### Q: ìƒì„±ëœ ìŒì•…ì´ ë„ˆë¬´ ë°˜ë³µì ì´ì—ìš”

**ì›ì¸**: Over-fitting ë˜ëŠ” temperature ë„ˆë¬´ ë‚®ìŒ

**í•´ê²°**:
1. Temperature ë†’ì´ê¸°: 0.9 â†’ 1.1
2. Top-p ë‚®ì¶”ê¸°: 0.95 â†’ 0.9
3. ë” ë§ì€ ë°ì´í„° ì¶”ê°€
4. Dropout ëŠ˜ë¦¬ê¸°: 0.1 â†’ 0.2

### Q: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)

**í•´ê²°**:
```python
# 1. Batch size ì¤„ì´ê¸°
per_device_train_batch_size = 2  # 4 â†’ 2

# 2. Gradient accumulation ëŠ˜ë¦¬ê¸°
gradient_accumulation_steps = 8  # 4 â†’ 8

# 3. Sequence length ì¤„ì´ê¸°
max_seq_len = 1024  # 2048 â†’ 1024

# 4. 4-bit quantization í™•ì¸
load_in_4bit = True  # ê¼­ True!
```

### Q: Lossê°€ ì•ˆ ì¤„ì–´ë“¤ì–´ìš”

**ì›ì¸**: Learning rate ë¬¸ì œ

**í•´ê²°**:
```python
# Learning rate ì¡°ì •
learning_rate = 1e-4  # 3e-4 â†’ 1e-4 (ë” ë‚®ê²Œ)

# ë˜ëŠ”
learning_rate = 5e-4  # 3e-4 â†’ 5e-4 (ë” ë†’ê²Œ)

# Warmup ëŠ˜ë¦¬ê¸°
warmup_steps = 200  # 100 â†’ 200
```

---

## 9ï¸âƒ£ ì‹¤ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°ì´í„° ì¤€ë¹„
- [ ] 50+ Brad Mehldau MIDI íŒŒì¼ ìˆ˜ì§‘
- [ ] í’ˆì§ˆ í™•ì¸ (ê¹¨ì§„ íŒŒì¼ ì œê±°)
- [ ] `data/brad_mehldau/` ë””ë ‰í† ë¦¬ì— ë°°ì¹˜

### í™˜ê²½ ì„¤ì •
- [ ] CUDA & cuDNN ì„¤ì¹˜
- [ ] `pip install -r production_transformer/requirements.txt`
- [ ] Weights & Biases ê³„ì • ìƒì„± & ë¡œê·¸ì¸

### Fine-tuning
- [ ] Dataset ìƒì„± & í™•ì¸
- [ ] Config íŒŒì¼ ì„¤ì • (`configs/qlora_default.yaml`)
- [ ] Training ì‹œì‘
- [ ] W&Bì—ì„œ loss ëª¨ë‹ˆí„°ë§

### í‰ê°€
- [ ] Validation loss < 1.5 í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ ìƒì„± (3-5ê°œ)
- [ ] ìŒì•…ì  í’ˆì§ˆ ì²­ì·¨

### ì‚¬ìš©
- [ ] ë§ˆìŒì— ë“œëŠ” checkpoint ì„ íƒ
- [ ] ì—¬ëŸ¬ temperature ì‹¤í—˜
- [ ] FL Studioì—ì„œ ìµœì¢… ì‘ì—…

---

## ğŸµ ë§ˆë¬´ë¦¬: í•µì‹¬ ì •ë¦¬

### 1. Tokenization (MIDI â†’ ìˆ«ì)
```
MIDI ì´ë²¤íŠ¸ â†’ í† í° ì‹œí€€ìŠ¤ â†’ AIê°€ ì´í•´ ê°€ëŠ¥
```

### 2. Fine-tuning (ìŠ¤íƒ€ì¼ í•™ìŠµ)
```
Pre-trained (ì¼ë°˜ ìŒì•…) + Brad MIDI â†’ Brad ìŠ¤íƒ€ì¼
99% frozen + 1% LoRA = íš¨ìœ¨ì !
```

### 3. Generation (ìƒˆë¡œìš´ ìŒì•…)
```
ì½”ë“œ ì…ë ¥ â†’ ëª¨ë¸ ì˜ˆì¸¡ â†’ í† í° ì‹œí€€ìŠ¤ â†’ MIDI íŒŒì¼
```

### 4. ì‹¤ì œ ì‚¬ìš©
```
50+ MIDI â†’ 5 epochs (3-6ì‹œê°„) â†’ Generate â†’ FL Studio
```

---

## ğŸ“ ìš°ë¦¬ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©ë²•

```bash
# 1. ë°ì´í„° ì¤€ë¹„
mkdir -p data/brad_mehldau
# MIDI íŒŒì¼ë“¤ì„ ì—¬ê¸°ì— ë³µì‚¬

# 2. Dataset ìƒì„±
cd production_transformer
python data/midi_dataset.py \
    --midi_dir ../data/brad_mehldau \
    --output_dir ../data/processed \
    --augment

# 3. Fine-tuning
python training/train.py \
    --data_dir ../data/processed \
    --output_dir ../experiments/brad_v1 \
    --use_qlora \
    --num_train_epochs 5 \
    --wandb_project "brad-mehldau"

# 4. ìƒì„±
python inference/generator.py \
    --checkpoint ../experiments/brad_v1/final_model \
    --prompt "Cmaj7 Am7 Dm7 G7" \
    --output ../output/solo.mid \
    --temperature 0.9 \
    --num_samples 5

# 5. Gradio ë°ëª¨ ì‹¤í–‰
python inference/gradio_demo.py \
    --checkpoint ../experiments/brad_v1/final_model \
    --port 7860

# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:7860 ì ‘ì†
```

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **Brad Mehldau MIDI ìˆ˜ì§‘** (50ê°œ ëª©í‘œ)
   - YouTube ì—°ì£¼ â†’ MIDI ë³€í™˜ (AnthemScore, Melodyne)
   - MIDI ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰

2. **ì²« ì‹¤í—˜** (ì‘ê²Œ ì‹œì‘)
   - 10ê°œ MIDIë¡œ í…ŒìŠ¤íŠ¸
   - 3 epochsë§Œ í•™ìŠµ
   - ê²°ê³¼ í™•ì¸

3. **ë³¸ê²© í•™ìŠµ** (ë§Œì¡±ìŠ¤ëŸ¬ìš°ë©´)
   - 50+ MIDIë¡œ í™•ì¥
   - 5-10 epochs
   - ìµœì  hyperparameter ì°¾ê¸°

4. **í”„ë¡œë•ì…˜**
   - Gradio ë°ëª¨ ê³µìœ 
   - FL Studio ì›Œí¬í”Œë¡œìš° í™•ë¦½
   - ì¹œêµ¬ë“¤ê³¼ ê³µìœ !

---

**ì´ì œ MIDI fine-tuningì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì™„ì „íˆ ì´í•´í•˜ì…¨ë‚˜ìš”?** ğŸ¹

ì§ˆë¬¸ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!
