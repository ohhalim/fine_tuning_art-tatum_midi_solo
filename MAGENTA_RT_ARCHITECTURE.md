# Magenta RealTime ì•„í‚¤í…ì²˜ ë¶„ì„

## ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Magenta RealTime System                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Input      â”‚â”€â”€â”€â”€â–¶â”‚   Style      â”‚â”€â”€â”€â”€â–¶â”‚   Output     â”‚â”‚
â”‚  â”‚              â”‚     â”‚   Control    â”‚     â”‚              â”‚â”‚
â”‚  â”‚ Text/Audio   â”‚     â”‚              â”‚     â”‚   Audio      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â”‚                    â”‚                    â–²         â”‚
â”‚         â”‚                    â”‚                    â”‚         â”‚
â”‚         â–¼                    â–¼                    â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           MusicCoCa (Style Encoder)                  â”‚  â”‚
â”‚  â”‚  - Text â†’ Embedding                                  â”‚  â”‚
â”‚  â”‚  - Audio â†’ Embedding                                 â”‚  â”‚
â”‚  â”‚  - RVQ Tokenization (6 layers Ã— 1024 codebook)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â”‚ Style Tokens (6,)               â”‚
â”‚                           â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Depthformer LLM (T5X-based)                  â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Encoder Input:                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚ Context Tokens (250 frames Ã— 4 RVQ)    â”‚         â”‚  â”‚
â”‚  â”‚  â”‚        + Style Tokens (6)               â”‚         â”‚  â”‚
â”‚  â”‚  â”‚  = 1006 tokens total                    â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Decoder Output:                                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚ Generated Tokens (50 frames Ã— 16 RVQ)  â”‚         â”‚  â”‚
â”‚  â”‚  â”‚  = 800 tokens per chunk                 â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Sampling Parameters:                                â”‚  â”‚
â”‚  â”‚  - Temperature: 1.1                                  â”‚  â”‚
â”‚  â”‚  - Top-K: 40                                         â”‚  â”‚
â”‚  â”‚  - Classifier-Free Guidance: 5.0                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â”‚ RVQ Tokens (50, 16)             â”‚
â”‚                           â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        SpectroStream Codec (Audio Decoder)           â”‚  â”‚
â”‚  â”‚  - RVQ â†’ Spectrogram                                 â”‚  â”‚
â”‚  â”‚  - 16 RVQ layers Ã— 1024 codebook                     â”‚  â”‚
â”‚  â”‚  - 25 fps frame rate                                 â”‚  â”‚
â”‚  â”‚  - 48kHz stereo output                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â”‚ Audio (96000 samples, 2 ch)     â”‚
â”‚                           â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Crossfade + State Update                   â”‚  â”‚
â”‚  â”‚  - 40ms crossfade between chunks                     â”‚  â”‚
â”‚  â”‚  - Context sliding window (10 seconds)               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š ë°ì´í„° í”Œë¡œìš°

### 1. Style Embedding (MusicCoCa)

```python
# Input
text_or_audio = "fast tempo jazz piano"
                 ë˜ëŠ”
                 Waveform(samples, sample_rate=48000)

# MusicCoCa ì²˜ë¦¬
style_embedding = magenta_rt.embed_style(text_or_audio)
# shape: (512,) - 512ì°¨ì› ë²¡í„°

# RVQ Tokenization
style_tokens = musiccoca.tokenize(style_embedding)
# shape: (6,) - 6ê°œì˜ ì´ì‚° í† í° (ê° 0-1023 ë²”ìœ„)

# LLM ì…ë ¥ìš© ë³€í™˜
style_tokens_lm = utils.rvq_to_llm(
    style_tokens,
    codebook_size=1024,
    offset=17140  # vocab_style_offset
)
# shape: (6,) - ë²”ìœ„ [17140, 23554)
```

### 2. Context ì¤€ë¹„

```python
# ì´ì „ ìƒì„± ê²°ê³¼ (ì´ˆê¸°: ë¹ˆ ìƒíƒœ)
context_tokens = state.context_tokens
# shape: (250, 16) - 10ì´ˆ ë¶„ëŸ‰ì˜ ì»¨í…ìŠ¤íŠ¸
#   250 frames = 10ì´ˆ (at 25 fps)
#   16 = RVQ depth

# Encoderìš©ìœ¼ë¡œ ì¼ë¶€ë§Œ ì‚¬ìš©
context_for_encoder = context_tokens[:, :4]  # ì²˜ìŒ 4 RVQ layersë§Œ
# shape: (250, 4) â†’ flatten â†’ (1000,)

# LLM ì…ë ¥ìš© ë³€í™˜
codec_tokens_lm = utils.rvq_to_llm(
    context_for_encoder,
    codebook_size=1024,
    offset=2  # vocab_codec_offset
)
# shape: (1000,) - ë²”ìœ„ [2, 16386)
```

### 3. LLM ì¶”ë¡ 

```python
# Encoder ì…ë ¥ êµ¬ì„±
encoder_inputs_pos = np.concatenate([
    codec_tokens_lm,    # (1000,) - ì»¨í…ìŠ¤íŠ¸
    style_tokens_lm     # (6,) - ìŠ¤íƒ€ì¼
])
# shape: (1006,)

# Classifier-Free Guidanceìš© negative prompt
encoder_inputs_neg = encoder_inputs_pos.copy()
encoder_inputs_neg[-6:] = MASK_TOKEN  # ìŠ¤íƒ€ì¼ ë§ˆìŠ¤í‚¹

# Batch êµ¬ì„±
encoder_inputs = np.stack([
    encoder_inputs_pos,  # Conditioned
    encoder_inputs_neg   # Unconditioned
])
# shape: (2, 1006)

# LLM ìƒì„±
generated_tokens, _ = llm(
    encoder_input_tokens=encoder_inputs,  # (2, 1006)
    decoder_input_tokens=zeros(2, 800),   # ì‹œì‘ í† í°ë“¤
    max_decode_steps=800,  # 50 frames Ã— 16 RVQ
    temperature=1.1,
    topk=40,
    guidance_weight=5.0
)
# shape: (2, 800)

# CFG ê²°í•©
# output = uncond + guidance_weight Ã— (cond - uncond)
final_tokens = generated_tokens[1] + 5.0 * (
    generated_tokens[0] - generated_tokens[1]
)
# shape: (800,) â†’ reshape â†’ (50, 16)
```

### 4. Audio ë””ì½”ë”©

```python
# RVQ í† í° â†’ LLM í† í° ì—­ë³€í™˜
rvq_tokens = utils.llm_to_rvq(
    final_tokens,
    codebook_size=1024,
    offset=2
)
# shape: (50, 16) - ê° ê°’ 0-1023 ë²”ìœ„

# Crossfadeë¥¼ ìœ„í•œ ì´ì „ í”„ë ˆì„ ì¶”ê°€
xfade_tokens = np.concatenate([
    state.context_tokens[-1:],  # ë§ˆì§€ë§‰ 1 frame (40ms)
    rvq_tokens                  # ìƒˆë¡œ ìƒì„±ëœ 50 frames
])
# shape: (51, 16)

# SpectroStream ë””ì½”ë”©
audio_with_xfade = codec.decode(xfade_tokens)
# shape: (97920, 2) - 51 frames Ã— 1920 samples/frame
#   = 2.04ì´ˆ (2ì´ˆ chunk + 40ms crossfade)

# Crossfade ì ìš©
chunk = audio_with_xfade[:-1920]  # 2ì´ˆ chunk
xfade_samples = audio_with_xfade[-1920:]  # 40ms overlap

# Equal-power crossfade
ramp = crossfade_ramp(1920, style='eqpower')
chunk[:1920] *= ramp
chunk[:1920] += state.crossfade_samples * (1 - ramp)

# Output
# shape: (96000, 2) - ì •í™•íˆ 2ì´ˆ @ 48kHz stereo
```

### 5. State ì—…ë°ì´íŠ¸

```python
# ì»¨í…ìŠ¤íŠ¸ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° (FIFO)
state.context_tokens = np.concatenate([
    state.context_tokens[50:],  # ì˜¤ë˜ëœ 50 frames ì œê±°
    rvq_tokens                  # ìƒˆë¡œìš´ 50 frames ì¶”ê°€
])
# í•­ìƒ (250, 16) ìœ ì§€ = 10ì´ˆ ì»¨í…ìŠ¤íŠ¸

# Crossfade ìƒ˜í”Œ ì €ì¥
state.crossfade_samples = xfade_samples

# Chunk ì¸ë±ìŠ¤ ì¦ê°€
state.chunk_index += 1
```

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### MagentaRTConfiguration

```python
@dataclass
class MagentaRTConfiguration:
    chunk_length: float = 2.0              # í•œ ë²ˆì— ìƒì„±í•  ê¸¸ì´ (ì´ˆ)
    context_length: float = 10.0           # LLMì´ ì°¸ì¡°í•  ì´ì „ ì˜¤ë””ì˜¤ (ì´ˆ)
    crossfade_length: float = 0.04         # Chunk ê°„ í¬ë¡œìŠ¤í˜ì´ë“œ (ì´ˆ)

    codec_sample_rate: int = 48000         # ì˜¤ë””ì˜¤ ìƒ˜í”Œë ˆì´íŠ¸
    codec_frame_rate: float = 25.0         # Codec í”„ë ˆì„ ë ˆì´íŠ¸
    codec_num_channels: int = 2            # ìŠ¤í…Œë ˆì˜¤
    codec_rvq_codebook_size: int = 1024    # RVQ ì½”ë“œë¶ í¬ê¸°

    encoder_codec_rvq_depth: int = 4       # Encoderì— ì‚¬ìš©í•  RVQ layers
    decoder_codec_rvq_depth: int = 16      # Decoderì—ì„œ ìƒì„±í•  RVQ layers

    encoder_style_rvq_depth: int = 6       # Style í† í° ê°œìˆ˜
    style_rvq_codebook_size: int = 1024    # Style RVQ ì½”ë“œë¶ í¬ê¸°
```

**ê³„ì‚° ì˜ˆì‹œ**:
```python
chunk_length_frames = 2.0ì´ˆ Ã— 25 fps = 50 frames
chunk_length_samples = 2.0ì´ˆ Ã— 48000 Hz = 96000 samples

context_length_frames = 10.0ì´ˆ Ã— 25 fps = 250 frames
context_length_samples = 10.0ì´ˆ Ã— 48000 Hz = 480000 samples

crossfade_length_frames = 0.04ì´ˆ Ã— 25 fps = 1 frame
crossfade_length_samples = 0.04ì´ˆ Ã— 48000 Hz = 1920 samples

encoder_input_size = (250 frames Ã— 4 RVQ) + 6 style = 1006 tokens
decoder_output_size = 50 frames Ã— 16 RVQ = 800 tokens

vocab_size = 2 (PAD+MASK) + 16384 (codec) + 1024 (unused) + 6144 (style) = 23554
```

### MagentaRTState

```python
class MagentaRTState:
    context_tokens: np.ndarray          # (250, 16) ì´ì „ ì˜¤ë””ì˜¤ í† í°
    crossfade_samples: Waveform         # (1920, 2) ë§ˆì§€ë§‰ 40ms ì˜¤ë””ì˜¤
    chunk_index: int                    # í˜„ì¬ ìƒì„± ì¤‘ì¸ chunk ë²ˆí˜¸

    def update(self, chunk_tokens, crossfade_samples):
        # FIFO: ì˜¤ë˜ëœ ë°ì´í„° ì œê±°, ìƒˆ ë°ì´í„° ì¶”ê°€
        self.context_tokens = np.concatenate([
            self.context_tokens[chunk_tokens.shape[0]:],
            chunk_tokens
        ])
        self.crossfade_samples = crossfade_samples
        self.chunk_index += 1
```

## ğŸ¯ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

### Classifier-Free Guidance (CFG)

```python
# ë‘ ê°€ì§€ ì¡°ê±´ìœ¼ë¡œ ìƒì„±
cond_output = model(context, style=style_tokens)        # ìŠ¤íƒ€ì¼ ì¡°ê±´ë¶€
uncond_output = model(context, style=MASK)              # ìŠ¤íƒ€ì¼ ë¬´ì¡°ê±´ë¶€

# ìŠ¤íƒ€ì¼ ì‹ í˜¸ ì¦í­
final = uncond + guidance_weight Ã— (cond - uncond)

# guidance_weight = 5.0
# â†’ ìŠ¤íƒ€ì¼ íŠ¹ì„±ì´ 5ë°° ê°•í•˜ê²Œ ë°˜ì˜ë¨
```

**íš¨ê³¼**: Text/Audio promptì˜ ì˜í–¥ë ¥ì„ ì¡°ì ˆí•˜ì—¬ ë” ëª…í™•í•œ ìŠ¤íƒ€ì¼ ì œì–´

### Equal-Power Crossfade

```python
def crossfade_ramp(n_samples, style='eqpower'):
    t = np.linspace(0, 1, n_samples)
    if style == 'eqpower':
        # Equal power law: ì—ë„ˆì§€ ë³´ì¡´
        return np.sqrt(t)
    elif style == 'linear':
        return t

# ì‚¬ìš© ì˜ˆì‹œ
fade_in = ramp              # 0 â†’ 1
fade_out = 1 - ramp         # 1 â†’ 0

# ë‘ chunk ê²°í•©
output = chunk_A * fade_out + chunk_B * fade_in
```

**íš¨ê³¼**: Chunk ê²½ê³„ì—ì„œ í´ë¦­ ë…¸ì´ì¦ˆ ì—†ì´ ë¶€ë“œëŸ¬ìš´ ì „í™˜

### RVQ Token ë³€í™˜

```python
def rvq_to_llm(rvq_tokens, codebook_size, offset):
    """RVQ ë‹¤ì¸µ í† í°ì„ LLM vocabìœ¼ë¡œ ë³€í™˜

    Input: (frames, depth)
    ê° ê°’: 0 ~ codebook_size-1

    Output: (frames, depth)
    ê° ê°’: offset + (layer_idx * codebook_size) + token_value
    """
    depth = rvq_tokens.shape[-1]
    layer_offsets = np.arange(depth) * codebook_size
    return offset + layer_offsets + rvq_tokens

# ì˜ˆì‹œ:
# rvq = [[5, 10, 15, 20]]  # 1 frame, 4 layers
# codebook_size = 1024
# offset = 2
#
# layer 0: 2 + 0Ã—1024 + 5 = 7
# layer 1: 2 + 1Ã—1024 + 10 = 1036
# layer 2: 2 + 2Ã—1024 + 15 = 2063
# layer 3: 2 + 3Ã—1024 + 20 = 3094
#
# llm_tokens = [[7, 1036, 2063, 3094]]
```

**ì´ìœ **: ê° RVQ layerëŠ” ë…ë¦½ì ì¸ ì •ë³´ë¥¼ ì¸ì½”ë”©í•˜ë¯€ë¡œ, vocab ê³µê°„ì—ì„œ ë¶„ë¦¬ í•„ìš”

## ğŸ’¡ ì„¤ê³„ ì² í•™

### 1. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”**
- Chunk ë‹¨ìœ„ ìƒì„± (2ì´ˆ)
- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œ (10ì´ˆ)
- Stateful ì„¤ê³„ (ì´ì „ ìƒíƒœ ì¬ì‚¬ìš©)

### 2. **ê³ í’ˆì§ˆ ì˜¤ë””ì˜¤**
- 16-layer RVQ â†’ ë†’ì€ fidelity
- 48kHz ìŠ¤í…Œë ˆì˜¤
- Equal-power crossfade â†’ ë¬´ì†ì‹¤ ê²°í•©

### 3. **ìœ ì—°í•œ ìŠ¤íƒ€ì¼ ì œì–´**
- Text + Audio í”„ë¡¬í”„íŠ¸ ì§€ì›
- ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ ë¸”ë Œë”©
- CFGë¡œ ì œì–´ ê°•ë„ ì¡°ì ˆ

### 4. **íš¨ìœ¨ì ì¸ í† í° ì‚¬ìš©**
- Encoder: 4 RVQ layers (ì••ì¶•)
- Decoder: 16 RVQ layers (ê³ í’ˆì§ˆ)
- Style: 6 í† í°ë§Œìœ¼ë¡œ ìŠ¤íƒ€ì¼ í‘œí˜„

## ğŸ”¬ ì„±ëŠ¥ íŠ¹ì„±

### ì§€ì—°ì‹œê°„ (Latency)
```
Chunk ìƒì„±: ~1-2ì´ˆ (GPU/TPU)
â””â”€ Style embedding: ~50ms
â””â”€ LLM inference: ~800ms
â””â”€ Audio decoding: ~100ms
â””â”€ Crossfade: ~10ms

ì‹¤ì‹œê°„ Factor: 1-2Ã— (2ì´ˆ ìƒì„±ì— 1-2ì´ˆ ì†Œìš”)
```

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
```
Model weights: ~1.5GB (large), ~500MB (base)
State: ~400KB
  â”œâ”€ context_tokens: (250, 16, 4 bytes) = 16KB
  â””â”€ crossfade_samples: (1920, 2, 4 bytes) = 15KB
JAX ì»´íŒŒì¼ ìºì‹œ: ~2GB
```

### í’ˆì§ˆ ì§€í‘œ
```
Sample rate: 48kHz (CD í’ˆì§ˆ ì´ˆê³¼)
Bit depth: 32-bit float
Channels: 2 (stereo)
RVQ layers: 16 (ë§¤ìš° ë†’ì€ ì••ì¶•ë¥  ëŒ€ë¹„ í’ˆì§ˆ)
Frequency response: 20Hz - 24kHz (Nyquist)
```

## ğŸ¼ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ìƒì„±
```python
from magenta_rt import system

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
magenta_rt = system.MagentaRT(tag='large', device='gpu')

# ìŠ¤íƒ€ì¼ ì„ë² ë”©
style = magenta_rt.embed_style("upbeat jazz piano solo")

# 30ì´ˆ ìƒì„±
chunks = []
state = None
for i in range(15):  # 15 chunks Ã— 2ì´ˆ = 30ì´ˆ
    chunk, state = magenta_rt.generate_chunk(
        state=state,
        style=style,
        temperature=1.1,  # ë‹¤ì–‘ì„± ì¡°ì ˆ
        topk=40,          # ìƒ˜í”Œë§ ë²”ìœ„
        guidance_weight=5.0  # ìŠ¤íƒ€ì¼ ê°•ë„
    )
    chunks.append(chunk)

# ê²°í•© ë° ì €ì¥
output = audio.concatenate(chunks)
output.write("output.wav")
```

### ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ ë¸”ë Œë”©
```python
# ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ ê²°í•©
styles = [
    magenta_rt.embed_style("classical piano"),
    magenta_rt.embed_style("jazz improvisation"),
    magenta_rt.embed_style("ambient pads")
]

# ê°€ì¤‘ í‰ê· 
weights = np.array([0.5, 0.3, 0.2])
blended_style = np.average(styles, axis=0, weights=weights)

# ìƒì„±
chunk, state = magenta_rt.generate_chunk(style=blended_style)
```

### ì˜¤ë””ì˜¤ í”„ë¡¬í”„íŠ¸
```python
# ê¸°ì¡´ ì˜¤ë””ì˜¤ë¥¼ ìŠ¤íƒ€ì¼ ì°¸ì¡°ë¡œ ì‚¬ìš©
reference = audio.Waveform.from_file("reference.wav")
style = magenta_rt.embed_style(reference)

# í•´ë‹¹ ìŠ¤íƒ€ì¼ë¡œ continuation ìƒì„±
chunk, state = magenta_rt.generate_chunk(style=style)
```

## ğŸš€ ìµœì í™” íŒ

### 1. Warm-up í•„ìš”
```python
# ì²« ìƒì„±ì€ ëŠë¦¼ (ëª¨ë¸ ë¡œë”© + JIT ì»´íŒŒì¼)
magenta_rt.warm_start()  # ~30ì´ˆ ì†Œìš”

# ì´í›„ ìƒì„±ì€ ë¹ ë¦„
```

### 2. Batch ì²˜ë¦¬ ë¶ˆê°€
```python
# í˜„ì¬ êµ¬í˜„ì€ batch_size=2 ê³ ì • (CFGìš©)
# ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ì„ ë³‘ë ¬ ìƒì„±í•˜ë ¤ë©´ multiple instances í•„ìš”
```

### 3. TPU ê¶Œì¥
```python
# TPUì—ì„œ GPU ëŒ€ë¹„ 2-3ë°° ë¹ ë¦„
magenta_rt = system.MagentaRT(device='tpu')
```

### 4. ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# Lazy loadingìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
magenta_rt = system.MagentaRT(lazy=True)

# ëª…ì‹œì  warm-up
magenta_rt.warm_start()  # í•„ìš”í•  ë•Œë§Œ ë¡œë”©
```

## ğŸ“š ê´€ë ¨ ì»´í¬ë„ŒíŠ¸

### SpectroStream (Codec)
- Audio â†” RVQ í† í° ë³€í™˜
- 16-layer RVQ
- 25 fps latency
- íŒŒì¼: `magenta_rt/spectrostream.py`

### MusicCoCa (Style Encoder)
- Text/Audio â†’ ì„ë² ë”©
- Contrastive learning
- 512ì°¨ì› ì„ë² ë”© ê³µê°„
- íŒŒì¼: `magenta_rt/musiccoca.py`

### Depthformer (LLM)
- T5X ê¸°ë°˜ Transformer
- Encoder-Decoder êµ¬ì¡°
- 2ê°€ì§€ í¬ê¸°: base (500M), large (1.5B)
- íŒŒì¼: `magenta_rt/depthformer/model.py`

## ğŸ”— ì°¸ê³  ìë£Œ

- [Magenta RealTime Paper](https://arxiv.org/abs/2501.xxxxx)
- [GitHub Repository](https://github.com/magenta/magenta-realtime)
- [Colab Demo](https://colab.research.google.com/github/magenta/magenta-realtime/blob/main/notebooks/Magenta_RT_Demo.ipynb)
